{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "\n",
    "YEAR_RANGE = (1900, 1950)\n",
    "\n",
    "def remove(row):\n",
    "    try:\n",
    "        date = dt.strptime(row.Date, '%Y-%m-%d')\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    if YEAR_RANGE and date.year >= YEAR_RANGE[0] and date.year <= YEAR_RANGE[1]:\n",
    "        pass # in the range!\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    if row['Exclude from visualization'] or row['Unsure whether drag artist']:\n",
    "        return True\n",
    "    \n",
    "    no_city = row['City'] == ''\n",
    "    no_performer = row['Performer'] == ''\n",
    "    no_venue = row['Venue'] == ''\n",
    "    unnamed_performer = 'unnamed' in row['Performer'].lower()\n",
    "    \n",
    "    if no_city and no_performer and no_venue:\n",
    "        return True\n",
    "    \n",
    "    if unnamed_performer:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def extract_addresses_dict(normalized_df):\n",
    "    addresses = {}\n",
    "    rows_with_addresses = normalized_df[normalized_df['Address']!='']\n",
    "    warnings = []\n",
    "    for x in zip(rows_with_addresses['Date'], rows_with_addresses['Source'], rows_with_addresses['Venue'], rows_with_addresses['Address']):\n",
    "        date, source, venue, address = x\n",
    "        if venue == '':\n",
    "            warnings.append(address)\n",
    "        else:\n",
    "            if not venue in addresses:\n",
    "                addresses[venue] = {}\n",
    "            if not source in addresses[venue]:\n",
    "                addresses[venue][source] = address\n",
    "    if len(warnings):\n",
    "        print(f'Warning: {len(warnings)} Venues with no names have addresses:')\n",
    "        print('- ' + '- '.join(warnings))\n",
    "\n",
    "    return addresses\n",
    "\n",
    "def reverse_comment_dict(comment_dict):\n",
    "    comments_reverse = {}\n",
    "    for performer, comments in comment_dict.items():\n",
    "        if not performer in comments_reverse:\n",
    "            comments_reverse[performer] = {}\n",
    "        for source, comment in comments.items():\n",
    "            if not comment in comments_reverse[performer]:\n",
    "                comments_reverse[performer][comment] = []\n",
    "            comments_reverse[performer][comment].append(source)\n",
    "    return comments_reverse\n",
    "        \n",
    "def get_comments(df, comment_field='Comment on edge: revue', match_field='Revue', transform=None):\n",
    "    comments = {}\n",
    "    rows_with_comments = df[df[comment_field]!='']\n",
    "    warnings = []\n",
    "    for x in zip(rows_with_comments['Date'], rows_with_comments['Source'], rows_with_comments[match_field], rows_with_comments[comment_field]):\n",
    "        date, source, match, comment = x\n",
    "        comment = str(comment).strip()\n",
    "        if transform:\n",
    "            comment = transform(comment)\n",
    "        if match == '':\n",
    "            warnings.append(str(comment)[:40]+'...')\n",
    "        else:\n",
    "            if not match in comments:\n",
    "                comments[match] = {}\n",
    "            if not source in comments[match]:\n",
    "                comments[match][source] = comment\n",
    "    if len(warnings):\n",
    "        print(f'Warning: {len(warnings)} mentions in `{comment_field}` with no value have comments:')\n",
    "        print('- ' + '\\n- '.join(warnings))\n",
    "\n",
    "    return comments\n",
    "\n",
    "def get_revue_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on edge: revue', 'Revue')\n",
    "\n",
    "def get_performer_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on node: performer', 'Performer')\n",
    "\n",
    "def get_venue_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on node: venue', 'Venue')\n",
    "\n",
    "def get_city_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on node: city', 'City')\n",
    "\n",
    "def get_true_value(row, type):\n",
    "    if type == 'source':\n",
    "        if row['Source clean'] != '':\n",
    "            return row['Source clean']\n",
    "        return row['Source']\n",
    "    if type == 'performer':\n",
    "        if row['Normalized performer'] != '':\n",
    "            return row['Normalized performer']\n",
    "        if row['Performer first-name'] != '' and row['Performer last-name'] != '':\n",
    "            return row['Normalized performer']\n",
    "        return row['Performer']\n",
    "    if type == 'city':\n",
    "        if row['Normalized City'] != '':\n",
    "            return row['Normalized City']\n",
    "        return row['City']\n",
    "    if type == 'revue':\n",
    "        if row['Normalized Revue Name'] != '':\n",
    "            return row['Normalized Revue Name']\n",
    "        return row['Revue name']\n",
    "    if type == 'venue':\n",
    "        if row['Normalized Venue'] != '':\n",
    "            return row['Normalized Venue']\n",
    "        return row['Venue']\n",
    "    raise NotImplementedError(f'type `{type}` is not yet implemented')\n",
    "\n",
    "def find_ref(row, eima=True):\n",
    "    source = row['Source']\n",
    "    source += ' ' + row['EIMA']\n",
    "    source += ' ' + row['Search (newspapers.com)']\n",
    "    source += ' ' + row['Source clean']\n",
    "    \n",
    "    is_eima = 'eima' in source.lower() or 'variety' in source.lower() or 'billboard' in source.lower()\n",
    "    has_ref = re.search(r'(\\d{7,10})', source)\n",
    "    refs = list(set(re.findall(r'(\\d{7,10})', source)))\n",
    "    if has_ref and eima and is_eima:\n",
    "        return '|'.join(refs)\n",
    "    \n",
    "    if has_ref and not eima and not is_eima:\n",
    "        return '|'.join(refs)\n",
    "\n",
    "    return ''\n",
    "    \n",
    "\n",
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT0E0Y7txIa2pfBuusA1cd8X5OVhQ_D0qZC8D40KhTU3xB7McsPR2kuB7GH6ncmNT3nfjEYGbscOPp0/pub?gid=0&single=true&output=csv')\n",
    "df = df.fillna('')\n",
    "df = df.replace('—', '')\n",
    "df = df.replace('—*', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set up our references to EIMA and newspapers.com\n",
    "df['EIMA'] = df.apply(lambda row: find_ref(row), axis=1)\n",
    "df['Newspapers.com'] = df.apply(lambda row: find_ref(row, False), axis=1)\n",
    "\n",
    "# Normalize dataframe\n",
    "df['Source'] = df.apply(lambda row: get_true_value(row, 'source'), axis=1)\n",
    "df['Venue'] = df.apply(lambda row: get_true_value(row, 'venue'), axis=1)\n",
    "df['Performer'] = df.apply(lambda row: get_true_value(row, 'performer'), axis=1)\n",
    "df['City'] = df.apply(lambda row: get_true_value(row, 'city'), axis=1)\n",
    "df['Revue'] = df.apply(lambda row: get_true_value(row, 'revue'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop filtered data\n",
    "df['remove'] = df.apply(lambda row: remove(row), axis=1)\n",
    "df = df.drop(df[df['remove']==True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = list(set([x for x in df['Source']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_NUMBERS = re.compile(r'\\d{6,10}')\n",
    "DATES = re.compile(r'(January|February|March|April|May|June|July|August|September|October|November|December) (\\d{1,2}), (\\d{4})')\n",
    "ENDS_WITH_PAGE = re.compile(r', (\\d{1,2})$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_without_id = [x for x in sources if not ID_NUMBERS.search(x)]\n",
    "\n",
    "sources_with_date = [x for x in sources_without_id if DATES.search(x)]\n",
    "\n",
    "sources_with_date = sorted(sources_with_date)\n",
    "\n",
    "\n",
    "papers = [DATES.split(x)[0][:-2] for x in sources_with_date]\n",
    "dates = [DATES.search(x).groups() for x in sources_with_date]\n",
    "# dates = [(x[2], x[0].replace('January', '01').replace('February', '02').replace('March', '03').replace('April', '04').replace('May', '05').replace('June', '06').replace('July', '07').replace('August', '08').replace('September', '09').replace('October', '10').replace('November', '11').replace('December', '12'), f'{int(x[1]):02d}') for x in dates]\n",
    "dates = [(x[2], x[0], x[1]) for x in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clear_page_number = [ENDS_WITH_PAGE.search(x) for x in sources_with_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_file = 'sources-data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "try:\n",
    "    b.get('http://www.newspapers.com')\n",
    "except:\n",
    "    b = webdriver.Firefox()\n",
    "    b.get('http://www.newspapers.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSING Aiken Standard  1934-January-24 (7/3796)\n",
      "DONE Aiken Standard --> https://www.newspapers.com/image/14191747\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1937-April-13 (8/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228680699\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-August-1 (9/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228836625\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1937-August-31 (10/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228732511\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-11 (11/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228473631\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-12 (12/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228474387\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-14 (13/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228475598\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-16 (14/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228476079\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-18 (15/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228476855\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-19 (16/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228477338\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-20 (17/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228477874\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-20 (18/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228477954\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-21 (19/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228478175/\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-21 (20/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228478372\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-21 (21/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228478260\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-4 (22/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228469894\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-5 (23/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228470742\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-6 (24/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228471624\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-7 (25/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228471864\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1935-December-9 (26/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228472328\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1936-February-26 (27/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228592629\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-24 (28/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228838872\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-25 (29/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228839244\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-26 (30/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228839808\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-28 (31/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228840583\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-29 (32/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228841236\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-30 (33/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228841851\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1930-July-31 (34/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228842640\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1936-November-27 (40/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228723274\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1937-October-25 (41/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228714313\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1937-October-27 (42/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228714629\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1937-October-30 (43/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228715121\n",
      "\n",
      "\n",
      "PROCESSING Akron Beacon Journal  1937-September-1 (44/3796)\n",
      "DONE Akron Beacon Journal --> https://www.newspapers.com/image/228655028\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-April-23 (165/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156636150\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1935-August-29 (166/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156593456\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-10 (167/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156256009\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-10 (168/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156256136\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-11 (169/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156256485\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-14 (170/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156257655\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-4 (171/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156254235\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-7 (172/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156255012\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-7 (173/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156255149\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-8 (174/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156255487\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-9 (175/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156255893\n",
      "\n",
      "\n",
      "PROCESSING Albuquerque Journal  1932-September-9 (176/3796)\n",
      "DONE Albuquerque Journal --> https://www.newspapers.com/image/156255600\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-December-1 (178/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274838378\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-December-5 (179/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274841577\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-December-7 (180/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274844212\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-December-7 (181/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274844258\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-February-23 (182/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274694063\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-June-9 (184/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274700730\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-March-23 (185/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274746924\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-May-9 (186/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274797327\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-November-24 (187/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274831101\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-November-26 (188/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274833324\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-November-27 (189/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274834496\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-November-30 (190/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274837666\n",
      "\n",
      "\n",
      "PROCESSING Allentown Morning Call  1935-October-25 (191/3796)\n",
      "DONE Allentown Morning Call --> https://www.newspapers.com/image/274789242\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1938-February-10 (192/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/26078630\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1938-February-26 (193/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/26082470\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1938-February-9 (194/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/26078309\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1934-June-19 (195/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/17499950/\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1937-May-20 (196/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/16326696\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1937-May-21 (197/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/16326714\n",
      "\n",
      "\n",
      "PROCESSING Alton Illinois Evening Telegraph  1937-October-26 (198/3796)\n",
      "DONE Alton Illinois Evening Telegraph --> https://www.newspapers.com/image/26083575\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Arizona Republic  1936-January-24 (212/3796)\n",
      "DONE Arizona Republic --> https://www.newspapers.com/image/117186988\n",
      "\n",
      "\n",
      "PROCESSING Arizona Republic  1936-May-29 (213/3796)\n",
      "DONE Arizona Republic --> https://www.newspapers.com/image/116955128\n",
      "\n",
      "\n",
      "PROCESSING Arizona Republic  1935-October-16 (214/3796)\n",
      "DONE Arizona Republic --> https://www.newspapers.com/image/117166064\n",
      "\n",
      "\n",
      "PROCESSING Asbury Park Press  1934-August-3 (215/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143319972\n",
      "\n",
      "\n",
      "PROCESSING Asbury Park Press  1934-August-4 (216/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143319993\n",
      "\n",
      "\n",
      "PROCESSING Asbury Park Press  1937-February-5 (217/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143340946\n",
      "\n",
      "\n",
      "PROCESSING Asbury Park Press  1935-July-3 (218/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143939270\n",
      "\n",
      "\n",
      "PROCESSING Asbury Park Press  1935-July-6 (219/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143939440\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Asbury Park Press  1934-June-20 (221/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143353765\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Asbury Park Press  1934-September-7 (223/3796)\n",
      "DONE Asbury Park Press --> https://www.newspapers.com/image/143926573\n",
      "\n",
      "\n",
      "PROCESSING Atlanta Constitution  1939-July-1 (224/3796)\n",
      "DONE Atlanta Constitution --> https://www.newspapers.com/image/398141666\n",
      "\n",
      "\n",
      "PROCESSING Atlanta Constitution  1939-July-2 (225/3796)\n",
      "DONE Atlanta Constitution --> https://www.newspapers.com/image/398145586\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Bakersfield Californian  1937-February-6 (233/3796)\n",
      "DONE Bakersfield Californian --> https://www.newspapers.com/image/1648053\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Baltimore Sun  1935-April-14 (345/3796)\n",
      "searching for newspaper Baltimore Sun\n",
      "--> skipping (due to ambivalent newspaper name)\n",
      "\n",
      "PROCESSING Barnard Bulletin  1930-February-25 (358/3796)\n",
      "DONE Barnard Bulletin --> https://www.newspapers.com/image/37829649\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Benton Harbor News-Palladium  1934-August-26 (361/3796)\n",
      "DONE Benton Harbor News-Palladium --> https://www.newspapers.com/image/364902662\n",
      "\n",
      "\n",
      "PROCESSING Berwyn Life  1935-June-14 (362/3796)\n",
      "DONE Berwyn Life --> https://www.newspapers.com/image/523669612\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Billings Gazette  1930-September-22 (722/3796)\n",
      "searching for newspaper Billings Gazette\n",
      "--> skipping (due to ambivalent newspaper name)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1930-August-30 (724/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/253687544\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1936-February-10 (725/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/252691059\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1935-February-11 (726/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/260604709\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1931-February-9 (727/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/253362374\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1931-February-9 (728/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/253362382\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1936-January-22 (729/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/252683583\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1936-January-30 (730/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/252686919\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1932-March-26 (732/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/253326284\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1932-March-28 (733/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/253326651\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1932-March-30 (734/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/253327341\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1934-November-22 (735/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/260539966\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1934-November-23 (736/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/260542152\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1934-November-26 (737/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/260544961\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1934-November-26 (738/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/260545089\n",
      "\n",
      "\n",
      "PROCESSING Binghamton Press and Sun-Bulletin  1934-November-28 (739/3796)\n",
      "DONE Binghamton Press and Sun-Bulletin --> https://www.newspapers.com/image/260548470\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Binghamton Press  1931-March-17 (742/3796)\n",
      "DONE Binghamton Press --> https://www.newspapers.com/image/253885638\n",
      "\n",
      "\n",
      "PROCESSING Bismarck Tribune  1937-June-16 (758/3796)\n",
      "DONE Bismarck Tribune --> https://www.newspapers.com/image/83114331/\n",
      "\n",
      "\n",
      "PROCESSING Bluefield Daily Telegraph  1934-March-25 (763/3796)\n",
      "DONE Bluefield Daily Telegraph --> https://www.newspapers.com/image/12317617\n",
      "\n",
      "\n",
      "PROCESSING Bluefield Daily Telegraph  1934-March-27 (764/3796)\n",
      "DONE Bluefield Daily Telegraph --> https://www.newspapers.com/image/12318858\n",
      "\n",
      "\n",
      "PROCESSING Bluefield Daily Telegraph  1934-March-28 (765/3796)\n",
      "DONE Bluefield Daily Telegraph --> https://www.newspapers.com/image/12319031\n",
      "\n",
      "\n",
      "PROCESSING Bluefield Daily Telegraph  1934-March-29 (766/3796)\n",
      "DONE Bluefield Daily Telegraph --> https://www.newspapers.com/image/12319634\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1931-April-13 (767/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/436965160\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1931-April-15 (768/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431256971\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1931-April-16 (769/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431226662\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSING Boston Globe  1933-April-17 (770/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431071868\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1933-April-19 (771/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431076440\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1936-April-22 (772/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/432014398\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1930-August-25 (773/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/430563426\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1930-August-26 (774/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/430563694\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1930-August-27 (775/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/430564084\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1931-July-20 (776/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431169656\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1931-July-21 (777/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431172019\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1931-July-24 (778/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431182330\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1936-March-18 (779/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431712148\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1933-March-20 (780/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/430597377\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Boston Globe  1933-May-15 (782/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431267923\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1933-May-16 (783/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431686642\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1933-May-17 (784/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431687472\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1937-October-18 (785/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/428621324\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1937-October-19 (786/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/428628645\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1937-October-20 (787/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/428630499\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1937-October-22 (788/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/428634774\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1937-October-23 (789/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/428637658\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1937-October-23 (790/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/428637682\n",
      "\n",
      "\n",
      "PROCESSING Boston Globe  1934-September-10 (791/3796)\n",
      "DONE Boston Globe --> https://www.newspapers.com/image/431762500\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Bradford Evening Star and The Bradford Daily Record  1935-August-31 (793/3796)\n",
      "DONE Bradford Evening Star and The Bradford Daily Record --> https://www.newspapers.com/image/76214902\n",
      "\n",
      "\n",
      "PROCESSING Bradford Evening Star and The Bradford Daily Record  1935-August-9 (794/3796)\n",
      "DONE Bradford Evening Star and The Bradford Daily Record --> https://www.newspapers.com/image/76214419\n",
      "\n",
      "\n",
      "PROCESSING Bradford Evening Star and The Bradford Daily Record  1935-December-31 (795/3796)\n",
      "DONE Bradford Evening Star and The Bradford Daily Record --> https://www.newspapers.com/image/76687351\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Bridgewater Courier-News  1936-December-11 (797/3796)\n",
      "DONE Bridgewater Courier-News --> https://www.newspapers.com/image/219421893\n",
      "\n",
      "\n",
      "PROCESSING Bridgewater Courier-News  1936-December-4 (798/3796)\n",
      "DONE Bridgewater Courier-News --> https://www.newspapers.com/image/219419175\n",
      "\n",
      "\n",
      "PROCESSING Bristol Daily Courier  1936-February-6 (799/3796)\n",
      "DONE Bristol Daily Courier --> https://www.newspapers.com/image/48636056\n",
      "\n",
      "\n",
      "PROCESSING Bristol Daily Courier  1936-January-11 (800/3796)\n",
      "DONE Bristol Daily Courier --> https://www.newspapers.com/image/48635557\n",
      "\n",
      "\n",
      "PROCESSING Bristol Daily Courier  1936-January-18 (801/3796)\n",
      "DONE Bristol Daily Courier --> https://www.newspapers.com/image/48635657\n",
      "\n",
      "\n",
      "PROCESSING Bristol Daily Courier  1936-January-23 (802/3796)\n",
      "DONE Bristol Daily Courier --> https://www.newspapers.com/image/48635731\n",
      "\n",
      "\n",
      "PROCESSING Bristol Daily Courier  1936-January-25 (803/3796)\n",
      "DONE Bristol Daily Courier --> https://www.newspapers.com/image/48635773\n",
      "\n",
      "\n",
      "PROCESSING Bristol Daily Courier  1936-January-30 (804/3796)\n",
      "have browse page for Bristol Daily Courier -- looking for first page for date\n",
      "finding page 4 for date 1936-January-30 in Bristol Daily Courier -- browsing from first page\n",
      "setting key to 3\n",
      "DONE Bristol Daily Courier --> https://www.newspapers.com/image/48635855\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1938-December-8 (813/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/543631952\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1932-February-20 (816/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542933413\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1931-February-22 (817/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542655917\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1932-January-2 (818/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542927333\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1930-July-29 (820/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542879174\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1934-May-11 (822/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/543592905\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1931-May-9 (825/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542860451\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1938-November-12 (826/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/543631639\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1938-November-5 (829/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/543631557\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1938-October-29 (830/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/543631428\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1931-October-3 (831/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542911418\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Citizen  1930-September-14 (832/3796)\n",
      "DONE Brooklyn Citizen --> https://www.newspapers.com/image/542881801\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1931-April-20 (833/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/57366056\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1935-August-12 (834/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/693805088\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1930-December-1 (836/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/58061441\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1939-December-1 (837/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52769415\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1939-December-15 (839/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52776174\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1939-December-22 (840/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52778317\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1939-December-29 (841/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52780159\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-December-9 (842/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/693865685\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1932-February-12 (843/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59867492\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1930-February-18 (845/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59908171\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1930-February-19 (846/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59908725\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1931-February-23 (847/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/57577547\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1933-February-6 (848/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59864658\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-January-17 (849/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59991210\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-January-29 (851/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59998832\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1935-July-22 (855/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52620411\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1933-June-16 (857/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59988275\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-June-19 (859/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59990833\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1931-March-21 (862/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59841534\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1932-March-24 (863/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/57401448\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1932-May-18 (868/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59971823\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-May-19 (870/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/58260824\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1936-May-20 (872/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/577442397\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-November-1 (874/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59971096\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1939-November-10 (875/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52759335\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1938-November-11 (876/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52621904\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-November-24 (878/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59992439\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1939-November-24 (879/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52767709\n",
      "\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to missing page number)\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1930-November-26 (882/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/58229157\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-November-26 (883/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59994228\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1934-November-27 (884/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/59994822\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1930-November-29 (885/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/58229221\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1938-November-4 (886/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/52617971\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Daily Eagle  1931-November-8 (887/3796)\n",
      "DONE Brooklyn Daily Eagle --> https://www.newspapers.com/image/57388147\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to missing page number)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Home Talk the Item  1931-April-1 (899/3796)\n",
      "DONE Brooklyn Home Talk the Item --> https://www.newspapers.com/image/576122848\n",
      "\n",
      "\n",
      "PROCESSING Brooklyn Home Talk the Item  1931-February-18 (900/3796)\n",
      "DONE Brooklyn Home Talk the Item --> https://www.newspapers.com/image/576121137\n",
      "\n",
      "--> skipping (due to date out of range)\n",
      "\n",
      "PROCESSING Brooklyn Home Talk the Item  1931-February-27 (902/3796)\n",
      "finding page 14 for date 1931-February-27 in Brooklyn Home Talk the Item -- browsing from first page\n",
      "setting key to 13\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 4000\n",
    "\n",
    "def get_current_variables():\n",
    "    try:\n",
    "        return json.loads(Path('data.json').read_text())\n",
    "    except FileNotFoundError:\n",
    "        print('could not load JSON so returning empty')\n",
    "        return {\n",
    "            'not_found': [],\n",
    "            'firstpage_urls': {},\n",
    "            'newspaper_urls': {},\n",
    "            'page_urls': {},\n",
    "            'ambiguous': [],\n",
    "            'no_link': {}\n",
    "        }\n",
    "    \n",
    "def set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link):\n",
    "    data = {\n",
    "        'not_found': not_found,\n",
    "        'firstpage_urls': firstpage_urls,\n",
    "        'newspaper_urls': newspaper_urls,\n",
    "        'page_urls': page_urls,\n",
    "        'ambiguous': ambiguous,\n",
    "        'no_link': no_link\n",
    "    }\n",
    "    Path('data.json').write_text(json.dumps(data))\n",
    "\n",
    "\n",
    "count = len([x for x in zip(papers, dates, clear_page_number)])\n",
    "counter = 0\n",
    "\n",
    "for newspaper, date, page in [x for x in zip(papers, dates, clear_page_number)][:LIMIT]:\n",
    "    counter += 1\n",
    "\n",
    "    not_found = get_current_variables()['not_found']\n",
    "    firstpage_urls = get_current_variables()['firstpage_urls']\n",
    "    newspaper_urls = get_current_variables()['newspaper_urls']\n",
    "    page_urls = get_current_variables()['page_urls']\n",
    "    ambiguous = get_current_variables()['ambiguous']\n",
    "    no_link = get_current_variables()['no_link']\n",
    "    \n",
    "    if newspaper.startswith(\"*\") or newspaper.startswith(\"-\") or 'date unknown' in newspaper:\n",
    "        # print('--> skipping (due to invalid name for newspaper)')\n",
    "        continue\n",
    "\n",
    "        \n",
    "    date_as_string = f'{date[0]}-{date[1]}-{date[2]}'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        print(no_link[newspaper_clean][date_as_string])\n",
    "        print('it is true so skip!')\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    if not page:\n",
    "        print('--> skipping (due to missing page number)')\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        page_urls[newspaper_clean][date_as_string][page]\n",
    "        print('--> skipping (due to already done)')\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    if int(date[0]) < 1930 or int(date[0]) > 1939:\n",
    "        print('--> skipping (due to date out of range)')\n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "    skip_ahead = False\n",
    "    \n",
    "    newspaper_clean = re.sub(r' [A-Z][A-Z] ', ' ', newspaper)\n",
    "    \n",
    "    if newspaper_clean in not_found or newspaper_clean in ambiguous:\n",
    "        # print('newspaper cannot be found', newspaper_clean)\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    print(\"PROCESSING\", newspaper_clean, f' {date[0]}-{date[1]}-{date[2]} ({counter}/{count})')\n",
    "    \n",
    "    if not newspaper_clean in newspaper_urls or newspaper_urls[newspaper_clean] == '':\n",
    "        newspaper_urls[newspaper_clean] = ''\n",
    "        if newspaper_urls[newspaper_clean] == '' or '#containing=' in newspaper_urls[newspaper_clean] or '/browse' in newspaper_urls[newspaper_clean]:\n",
    "            print('searching for newspaper', newspaper_clean)\n",
    "            b.get('https://www.newspapers.com/papers/')\n",
    "            time.sleep(3)\n",
    "            b.find_element_by_css_selector('[name=\"filtertext\"]').send_keys(newspaper_clean)\n",
    "            time.sleep(1)\n",
    "            b.find_element_by_css_selector('[name=\"filtertext\"]').send_keys(Keys.ENTER)\n",
    "            time.sleep(5)\n",
    "            if b.find_element_by_css_selector(\"#noresults\"):\n",
    "                if 'nothing matched your search' in b.find_element_by_css_selector(\"#noresults\").text:\n",
    "                    print('could not find newspaper', newspaper_clean, '-- searched for', newspaper_clean)\n",
    "                    not_found.append(newspaper_clean)\n",
    "                    set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "                    skip_ahead = True\n",
    "            if b.find_elements_by_css_selector('.record-result'):\n",
    "                if len(b.find_elements_by_css_selector('.record-result')) == 1:\n",
    "                    b.find_elements_by_css_selector('.record-result')[0]\n",
    "                    b.find_elements_by_css_selector('.record-result')[0].find_elements_by_tag_name('a')[0].click()\n",
    "                    time.sleep(3)\n",
    "                    newspaper_url = b.current_url\n",
    "                    newspaper_urls[newspaper_clean] = newspaper_url\n",
    "                else:\n",
    "                    test = [x for x in b.find_elements_by_css_selector('.record-result') if x.find_element_by_tag_name('h2').text == newspaper_clean]\n",
    "                    if len(test) == 1:\n",
    "                        test[0].find_elements_by_tag_name('a')[0].click()\n",
    "                        time.sleep(3)\n",
    "                        newspaper_url = b.current_url\n",
    "                        newspaper_urls[newspaper_clean] = newspaper_url                        \n",
    "                    else:\n",
    "                        ambiguous.append(newspaper_clean)\n",
    "                        set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "                        print('--> skipping (due to ambivalent newspaper name)')\n",
    "                        skip_ahead = True\n",
    "\n",
    "    \n",
    "    \n",
    "    if skip_ahead:\n",
    "        continue\n",
    "        \n",
    "    set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "    not_found = get_current_variables()['not_found']\n",
    "    firstpage_urls = get_current_variables()['firstpage_urls']\n",
    "    newspaper_urls = get_current_variables()['newspaper_urls']\n",
    "    page_urls = get_current_variables()['page_urls']\n",
    "    ambiguous = get_current_variables()['ambiguous']\n",
    "    no_link = get_current_variables()['no_link']\n",
    "\n",
    "    \n",
    "    if not newspaper_clean in firstpage_urls:\n",
    "        firstpage_urls[newspaper_clean] = {}\n",
    "    \n",
    "    if not date_as_string in firstpage_urls[newspaper_clean] or not '/image/' in firstpage_urls[newspaper_clean][date_as_string]:\n",
    "        print(f'have browse page for {newspaper_clean} -- looking for first page for date')\n",
    "        b.get(newspaper_urls[newspaper_clean])\n",
    "        time.sleep(3)\n",
    "\n",
    "        try:\n",
    "            # choose year\n",
    "            b.find_element_by_id('datepicker_year_combobox').send_keys(date[0])\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            b.find_element_by_id('datepicker_year_combobox').send_keys(date[0])\n",
    "            time.sleep(3)\n",
    "\n",
    "        # choose month\n",
    "        select = Select(b.find_element_by_id('select_month'))\n",
    "        select.select_by_visible_text(date[1])\n",
    "        time.sleep(3)\n",
    "\n",
    "        # choose day\n",
    "        day_element = [x for x in b.find_elements_by_class_name('calendar_option') if x.text == date[2]][0]\n",
    "        try:\n",
    "            day_element.find_element_by_tag_name('a')\n",
    "            day_element.click()\n",
    "            time.sleep(3)\n",
    "\n",
    "            if not date_as_string in firstpage_urls[newspaper_clean]:\n",
    "                firstpage_urls[newspaper_clean][date_as_string] = b.current_url\n",
    "        except NoSuchElementException:\n",
    "            if not newspaper_clean in no_link:\n",
    "                no_link[newspaper_clean] = {}\n",
    "            if not date_as_string in no_link[newspaper_clean]:\n",
    "                no_link[newspaper_clean][date_as_string] = True\n",
    "            print('--> skipping (due to missing date)')\n",
    "            skip_ahead = True\n",
    "    \n",
    "    \n",
    "    if skip_ahead:\n",
    "        continue\n",
    "        \n",
    "\n",
    "    set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "    not_found = get_current_variables()['not_found']\n",
    "    firstpage_urls = get_current_variables()['firstpage_urls']\n",
    "    newspaper_urls = get_current_variables()['newspaper_urls']\n",
    "    page_urls = get_current_variables()['page_urls']\n",
    "    ambiguous = get_current_variables()['ambiguous']\n",
    "    no_link = get_current_variables()['no_link']\n",
    "\n",
    "    page = page.groups()[0]\n",
    "    if not newspaper_clean in page_urls:\n",
    "        page_urls[newspaper_clean] = {}\n",
    "    \n",
    "    if not date_as_string in page_urls[newspaper_clean]:\n",
    "        page_urls[newspaper_clean][date_as_string] = {}\n",
    "        \n",
    "    if not page in page_urls[newspaper_clean][date_as_string]:\n",
    "        if firstpage_urls[newspaper_clean][date_as_string].startswith('https://www.newspapers.com/paper'):\n",
    "            skip_ahead = True\n",
    "            del firstpage_urls[newspaper_clean][date_as_string]\n",
    "            set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "        else:\n",
    "            print(f'finding page {page} for date {date_as_string} in {newspaper_clean} -- browsing from first page')\n",
    "\n",
    "            b.get(firstpage_urls[newspaper_clean][date_as_string])\n",
    "            time.sleep(2)\n",
    "\n",
    "            if int(page) > 1:\n",
    "                print(f'setting key to {int(page)-1}')\n",
    "                b.find_element_by_id('filmstrip_pagenum_target_input').send_keys(int(page)-1)\n",
    "                b.find_element_by_id('filmstrip_pagenum_target_input').send_keys(Keys.ENTER)\n",
    "            \n",
    "            max_count = int(b.find_element_by_id('filmstrip_total_edition_count').text)\n",
    "            if int(max_count) > int(page):\n",
    "                continue\n",
    "            else:\n",
    "                current = b.find_element_by_id('filmstrip_pagenum_target_input').get_attribute('value')\n",
    "                while not int(current) == int(page):\n",
    "                    b.find_element_by_css_selector('a[title=\"Next page\"]').click()\n",
    "                    time.sleep(1)\n",
    "                    current = int(b.find_element_by_id('filmstrip_pagenum_target_input').get_attribute('value'))\n",
    "\n",
    "                page_url = b.current_url\n",
    "\n",
    "                if not newspaper_clean in page_urls:\n",
    "                    page_urls[newspaper_clean] = {}\n",
    "\n",
    "                if not date_as_string in page_urls[newspaper_clean]:\n",
    "                    page_urls[newspaper_clean][date_as_string] = {}\n",
    "\n",
    "                page_urls[newspaper_clean][date_as_string][page] = page_url\n",
    "\n",
    "    \n",
    "    if skip_ahead:\n",
    "        continue\n",
    "        \n",
    "    set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "\n",
    "    print(\"DONE\", newspaper_clean, '-->', page_urls[newspaper_clean][date_as_string][page])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Amsterdam Evening Recorder\n",
    "Baldwinsville Gazette and Farmers Journal\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baltimore Afro-American',\n",
       " 'Billboard',\n",
       " 'Binghamton Press and Sun-Bulletin',\n",
       " 'Boston Globe',\n",
       " 'Chicago Defender',\n",
       " 'Cincinnati Enquirer',\n",
       " 'Daily News',\n",
       " 'Daily Oklahoman',\n",
       " 'Dayton Daily News',\n",
       " 'Dayton Herald',\n",
       " 'Des Moines Register',\n",
       " 'Des Moines Tribune',\n",
       " 'Detroit Free Press',\n",
       " 'Dunkirk Evening Observer',\n",
       " 'Elmira Star-Gazette',\n",
       " 'Evening Sun',\n",
       " 'Glens Falls Post-Star',\n",
       " 'Miami Daily News',\n",
       " 'Oakland Tribune',\n",
       " 'San Antonio Light',\n",
       " 'Washington Evening Star']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_newspapers(df, start_year=1930, end_year=1940):\n",
    "    remaining = []\n",
    "    newspaper_urls = get_current_variables()['newspaper_urls']\n",
    "    has_content = [x for x in newspaper_urls if newspaper_urls]\n",
    "    for newspaper, row in df.groupby('Newspaper'):\n",
    "        newspaper = re.sub(r' [A-Z][A-Z] ', ' ', newspaper)\n",
    "        if newspaper.startswith('*') or newspaper == \"\":\n",
    "            continue\n",
    "            \n",
    "        valid = 1930 > int(min([x[:4] for x in row.Date]))\n",
    "        valid = 1940 < int(max([x[:4] for x in row.Date]))\n",
    "        \n",
    "        if not valid:\n",
    "            continue\n",
    "\n",
    "        if newspaper in has_content:\n",
    "            continue\n",
    "            \n",
    "        has_articles_in_range = [x for x in row['Source clean'] if not re.search('\\d{6,10}', x) and ('1930' in x or '1931' in x or '1932' in x or '1933' in x or '1934' in x or '1935' in x or '1936' in x or '1937' in x or '1938' in x or '1939' in x)]\n",
    "\n",
    "        if not has_articles_in_range:\n",
    "            continue\n",
    "            \n",
    "        remaining.append(newspaper)\n",
    "    \n",
    "    return remaining\n",
    "    \n",
    "get_newspapers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Alexandria Town Talk': 'The Town Talk\\nAlexandria, Louisiana',\n",
    "    'Binghamton Press and Sun-Bulletin': 'Press and Sun-Bulletin\\nBinghamton, New York',\n",
    "    \"Boston Globe\": \"The Boston Globe\\nBoston, Massachusetts\",\n",
    "    \"Cincinnati Enquirer\": \"The Cincinnati Enquirer\",\n",
    "    \"Daily Oklahoman\": \"The Daily Oklahoman\",\n",
    "    \"Dayton Daily News\": \"Dayton Daily News\\nDayton, Ohio\",\n",
    "    \"Dayton Herald\": \"The Dayton Herald\\nDayton, Ohio\",\n",
    "    \"Des Moines Register\": \"The Des Moines Register\\nDes Moines, Iowa\",\n",
    "    \"Des Moines Tribune\": \"Des Moines Tribune\\nDes Moines, Iowa\",\n",
    "    \"Detroit Free Press\": \"Detroit Free Press\\nDetroit, Michigan\",\n",
    "    \"Dunkirk Evening Observer\": \"Dunkirk Evening Observer\\nDunkirk, New York\",\n",
    "    \"Elmira Star-Gazette\": \"Star-Gazette\\nElmira, New York\",\n",
    "    \"Glens Falls Post-Star\": \"The Post-Star\\nGlens Falls, New York\",\n",
    "    \"Oakland Tribune\": \"Oakland Tribune\\nOakland, California\",\n",
    "    \"San Antonio Light\": \"San Antonio Light\\nSan Antonio, Texas\",\n",
    "    \"Washington Evening Star\": \"Evening Star\\nWashington, District of Columbia\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['Baltimore Afro-American', 'Chicago Defender', 'Billboard', 'Hollywood Reporter', 'Daily News', 'Evening Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = sorted([re.sub(' [A-Z][A-Z] ',' ',x) for x in set(df['Newspaper']) if x and re.sub(' [A-Z][A-Z] ',' ',x) not in firstpage_urls.keys() and not x.startswith('*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching for newspaper Miami Daily News\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: Browsing context has been discarded\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-05cc00a7e260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewspaper_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewspaper_clean\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'#containing='\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewspaper_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewspaper_clean\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'/browse'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewspaper_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewspaper_clean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'searching for newspaper'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewspaper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.newspapers.com/papers/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[name=\"filtertext\"]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewspaper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: Browsing context has been discarded\n"
     ]
    }
   ],
   "source": [
    "for newspaper in get_newspapers(df):\n",
    "    not_found = get_current_variables()['not_found']\n",
    "    firstpage_urls = get_current_variables()['firstpage_urls']\n",
    "    newspaper_urls = get_current_variables()['newspaper_urls']\n",
    "    page_urls = get_current_variables()['page_urls']\n",
    "    ambiguous = get_current_variables()['ambiguous']\n",
    "    no_link = get_current_variables()['no_link']\n",
    "\n",
    "    if newspaper in excluded:\n",
    "        continue\n",
    "        \n",
    "    if not newspaper in newspaper_urls or newspaper_urls[newspaper_clean] == '':\n",
    "        newspaper_urls[newspaper_clean] = ''\n",
    "        if newspaper_urls[newspaper_clean] == '' or '#containing=' in newspaper_urls[newspaper_clean] or '/browse' in newspaper_urls[newspaper_clean]:\n",
    "            print('searching for newspaper', newspaper)\n",
    "            b.get('https://www.newspapers.com/papers/')\n",
    "            time.sleep(3)\n",
    "            b.find_element_by_css_selector('[name=\"filtertext\"]').send_keys(newspaper)\n",
    "            time.sleep(1)\n",
    "            b.find_element_by_css_selector('[name=\"filtertext\"]').send_keys(Keys.ENTER)\n",
    "            time.sleep(3)\n",
    "\n",
    "            if b.find_element_by_css_selector(\"#noresults\"):\n",
    "                if 'nothing matched your search' in b.find_element_by_css_selector(\"#noresults\").text:\n",
    "                    print('could not find newspaper', newspaper_clean, '-- searched for', newspaper_clean)\n",
    "                    not_found.append(newspaper_clean)\n",
    "                    set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "                    skip_ahead = True\n",
    "            if b.find_elements_by_css_selector('.record-result'):\n",
    "                if len(b.find_elements_by_css_selector('.record-result')) == 1:\n",
    "                    b.find_elements_by_css_selector('.record-result')[0]\n",
    "                    b.find_elements_by_css_selector('.record-result')[0].find_elements_by_tag_name('a')[0].click()\n",
    "                    time.sleep(3)\n",
    "                    newspaper_url = b.current_url\n",
    "                    newspaper_urls[newspaper_clean] = newspaper_url\n",
    "                else:\n",
    "                    test = [x for x in b.find_elements_by_css_selector('.record-result') if x.find_element_by_tag_name('h2').text == newspaper_clean]\n",
    "                    if len(test) == 1:\n",
    "                        test[0].find_elements_by_tag_name('a')[0].click()\n",
    "                        time.sleep(3)\n",
    "                        newspaper_url = b.current_url\n",
    "                        newspaper_urls[newspaper_clean] = newspaper_url                        \n",
    "                    else:\n",
    "                        test = [x for x in b.find_elements_by_css_selector('.record-result') if mapping[newspaper] in x.text]\n",
    "                        if len(test) == 1:\n",
    "                            test[0].find_elements_by_tag_name('a')[0].click()\n",
    "                            time.sleep(3)\n",
    "                            newspaper_url = b.current_url\n",
    "                            newspaper_urls[newspaper_clean] = newspaper_url                        \n",
    "                        else:\n",
    "                            ambiguous.append(newspaper_clean)\n",
    "                            set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n",
    "                            print('--> skipping (due to ambivalent newspaper name)')\n",
    "                            skip_ahead = True\n",
    "\n",
    "\n",
    "    set_current_variables(not_found, firstpage_urls, newspaper_urls, page_urls, ambiguous, no_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aiken Standard',\n",
       " 'Akron Beacon Journal',\n",
       " 'Albuquerque Journal',\n",
       " 'Allentown Morning Call',\n",
       " 'Alton Illinois Evening Telegraph',\n",
       " 'American Israelite',\n",
       " 'Arizona Republic',\n",
       " 'Asbury Park Press',\n",
       " 'Atlanta Constitution',\n",
       " 'Bakersfield Californian',\n",
       " 'Bakersfield Morning Echo',\n",
       " 'Barnard Bulletin',\n",
       " 'Benton Harbor News-Palladium',\n",
       " 'Berwyn Life',\n",
       " 'Brooklyn Daily Eagle',\n",
       " 'Camden Courier-Post',\n",
       " 'Hackensack Record',\n",
       " 'Harlingen Valley Morning Star',\n",
       " 'Harrisburg Sunday Courier',\n",
       " 'Harrisburg Telegraph',\n",
       " 'Hartford Courant',\n",
       " 'Hazleton Plain Speaker',\n",
       " 'Hazleton Standard-Speaker',\n",
       " 'Helper Journal',\n",
       " 'Herald-Journal',\n",
       " 'Herald-Press',\n",
       " 'Hollywood Reporter',\n",
       " 'Honolulu Star-Bulletin',\n",
       " 'Huntsville Times',\n",
       " 'Idaho Falls Post-Register',\n",
       " 'Independent-Record',\n",
       " 'Indianapolis News',\n",
       " 'Indianapolis Star',\n",
       " 'Indianapolis Times',\n",
       " 'Ithaca Journal',\n",
       " 'Ithaca Journal-News',\n",
       " 'Jackson Clarion-Ledger',\n",
       " 'Johnson City Chronicle',\n",
       " 'Johnson City Staff-News',\n",
       " 'Journal',\n",
       " 'Journal News',\n",
       " 'Journal Times',\n",
       " 'Kane Republican',\n",
       " 'Kansas City Star',\n",
       " 'Kansas City Times',\n",
       " 'Kenosha News',\n",
       " 'Keyport Weekly',\n",
       " 'Kingston Daily Freeman',\n",
       " 'Knickerbocker Press',\n",
       " 'Knoxville Journal',\n",
       " 'Knoxville News-Sentinel',\n",
       " 'Lancaster Eagle-Gazette',\n",
       " 'Lancaster New Era',\n",
       " 'Lansing State Journal',\n",
       " 'Lima News',\n",
       " 'Lincoln Journal Star',\n",
       " 'Lincoln Star',\n",
       " 'Long Island Daily Press',\n",
       " 'Los Angeles Evening Citizen News',\n",
       " 'Los Angeles Evening Post-Record',\n",
       " 'Los Angeles Illustrated Daily News',\n",
       " 'Los Angeles Times',\n",
       " 'Louisville Courier-Journal',\n",
       " 'Lowville Journal and Republican',\n",
       " 'Macon Chronicle-Herald',\n",
       " 'Mansfield News-Journal',\n",
       " 'Marion Star',\n",
       " 'Marysville Journal-Tribune',\n",
       " 'Matawan Journal',\n",
       " 'Meramec Valley Transcript',\n",
       " 'Meriden Daily Journal',\n",
       " 'Messenger-Inquirer',\n",
       " 'Miami Herald',\n",
       " 'Miami News',\n",
       " 'Miami Tribune',\n",
       " 'Milwaukee Jewish Chronicle',\n",
       " 'Minneapolis Star Tribune',\n",
       " 'Moline Dispatch',\n",
       " 'Montgomery Advertiser',\n",
       " 'Morning Call',\n",
       " 'Morning News',\n",
       " 'Morning Post',\n",
       " 'Muncie Evening Press',\n",
       " 'Munster Times',\n",
       " 'Muscatine Journal',\n",
       " 'Nashville Banner',\n",
       " 'Nashville Daily News-Journal',\n",
       " 'Nassau Daily Herald',\n",
       " 'Nassau Daily Review',\n",
       " 'Nebraska State Journal',\n",
       " 'Nevada State Journal',\n",
       " 'New Brunswick Daily Home News',\n",
       " 'New Castle News',\n",
       " 'New York Age',\n",
       " 'New York Daily News',\n",
       " 'New York Evening Post',\n",
       " 'New York Herald Tribune',\n",
       " 'New York Post',\n",
       " 'New York Sun',\n",
       " 'New York Times',\n",
       " 'Newark Advocate',\n",
       " 'Newburgh News',\n",
       " 'News',\n",
       " 'News Tribune',\n",
       " 'News-Palladium',\n",
       " 'North Adams Transcript',\n",
       " 'North Tonawanda Evening News',\n",
       " 'Ogden Standard-Examiner',\n",
       " 'Oklahoma News',\n",
       " 'Olean Times Herald',\n",
       " 'Owensboro Messenger',\n",
       " 'Paterson Morning Call',\n",
       " 'Paterson News',\n",
       " 'Philadelphia Inquirer',\n",
       " 'Pittsburgh Courier',\n",
       " 'Pittsburgh Post-Gazette',\n",
       " 'Pittsburgh Press',\n",
       " 'Pittsburgh Sun-Telegraph',\n",
       " 'Plattsburgh Daily Press',\n",
       " 'Pomona Progress Bulletin',\n",
       " 'Port Chester Daily Item',\n",
       " 'Pottstown Mercury',\n",
       " 'Pottsville Republican and Herald',\n",
       " 'Poughkeepsie Eagle News',\n",
       " 'Racine Journal Times',\n",
       " 'Reading Times',\n",
       " 'Record',\n",
       " 'Record-Journal',\n",
       " 'Reno Nevada State Journal',\n",
       " 'Richmond Item',\n",
       " 'Richmond Palladium and Sun-Telegram',\n",
       " 'Richmond Palladium-Item',\n",
       " 'Richmond Times Dispatch',\n",
       " 'Ridgewood Herald',\n",
       " 'Ridgewood Herald-News',\n",
       " 'Ridgewood Sunday News',\n",
       " 'Rochester Democrat and Chronicle',\n",
       " 'Rochester Times-Union',\n",
       " 'Rock Island Argus',\n",
       " 'Rome Daily Sentinel',\n",
       " 'Russell Register',\n",
       " 'Rutherford Courier',\n",
       " 'Saint Joseph Herald-Press',\n",
       " 'Salem News',\n",
       " 'Salem Statesman Journal',\n",
       " 'Salinas Californian',\n",
       " 'Salinas Morning Post',\n",
       " 'Salt Lake Tribune',\n",
       " 'San Francisco Examiner',\n",
       " 'San Mateo Times',\n",
       " 'Sandusky Register',\n",
       " 'Santa Fe New Mexican',\n",
       " 'Santa Rosa Republican',\n",
       " 'Saratogian',\n",
       " 'Schenectady Gazette',\n",
       " 'Scranton Times-Tribune',\n",
       " 'Scranton Tribune',\n",
       " 'Sedalia Democrat',\n",
       " 'Shamokin News-Dispatch',\n",
       " 'Sheboygan Press',\n",
       " 'Shreveport Journal',\n",
       " 'Shreveport Times',\n",
       " 'Sioux City Journal',\n",
       " 'Smithtown Star',\n",
       " 'South Bend Tribune',\n",
       " 'Spokane Spokesman-Review',\n",
       " 'St. Joseph Gazette',\n",
       " 'St. Louis Globe-Democrat',\n",
       " 'St. Louis Star and Times',\n",
       " 'Standard Union',\n",
       " 'Standard-Sentinel',\n",
       " 'Star Press',\n",
       " 'Stockton Independent',\n",
       " 'Student Life',\n",
       " 'Sun-Advocate',\n",
       " 'Sunday Journal and Star',\n",
       " 'Syracuse American',\n",
       " 'Syracuse Journal',\n",
       " 'Tennessean',\n",
       " 'The Billboard',\n",
       " 'Times Union',\n",
       " 'Times and Democrat',\n",
       " 'Tonawanda Evening News',\n",
       " 'Troy Messenger',\n",
       " 'Troy Times',\n",
       " 'Troy Times Record',\n",
       " 'Utica Observer-Dispatch',\n",
       " 'Vancouver News-Herald',\n",
       " 'Vancouver Sun',\n",
       " 'Variety',\n",
       " 'Vineland Daily Journal',\n",
       " 'Visalia Times-Delta',\n",
       " 'Warren Times Mirror',\n",
       " 'Warrenton Banner',\n",
       " 'Waterloo Courier',\n",
       " 'Wilkes-Barre Times Leader',\n",
       " 'Wilmington Morning News',\n",
       " 'Wilmington News Journal',\n",
       " 'Windsor Star',\n",
       " 'Wisconsin Jewish Chronicle',\n",
       " \"Women's Wear Daily\",\n",
       " 'Women’s Wear Daily',\n",
       " 'Yonkers Herald',\n",
       " 'Yonkers Statesman',\n",
       " 'York Daily Record',\n",
       " 'Zanesville Signal',\n",
       " 'Zanesville Times Recorder']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([x for x in newspaper_urls.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_variables()['newspaper_urls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Town Talk\\nAlexandria, Louisiana\\n1,723,513 pages']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Binghamton Press and Sun-Bulletin\": \"https://www.newspapers.com/paper/press-and-sun-bulletin/3799/\",\n",
    "\"Boston Globe\": \"https://www.newspapers.com/paper/the-boston-globe/9077/\",\n",
    "\"Cincinnati Enquirer\": \"https://www.newspapers.com/paper/the-cincinnati-enquirer/844/\",\n",
    "\"Daily Oklahoman\": \"https://www.newspapers.com/paper/the-daily-oklahoman/2087/\",\n",
    "\"Dayton Daily News\": \"https://www.newspapers.com/paper/dayton-daily-news/7809/\",\n",
    "\"Dayton Herald\": \"https://www.newspapers.com/paper/the-dayton-herald/7803/\",\n",
    "\"Des Moines Register\": \"https://www.newspapers.com/paper/the-des-moines-register/86/\",\n",
    "\"Des Moines Tribute\": \"https://www.newspapers.com/paper/des-moines-tribune/84/\",\n",
    "\"Detroit Free Press\": \"https://www.newspapers.com/paper/detroit-free-press/3676/\",\n",
    "\"Dunkirk Evening Observer\": \"https://www.newspapers.com/paper/dunkirk-evening-observer/500/\",\n",
    "\"Elmira Star-Gazette\": \"https://www.newspapers.com/paper/star-gazette/3800/\",\n",
    "\"Oakland Tribune\": \"https://www.newspapers.com/paper/oakland-tribune/2/\",\n",
    "\"San Antonio Light\": \"https://www.newspapers.com/paper/san-antonio-light/607/\",\n",
    "\"Washington Evening Star\": \"https://www.newspapers.com/paper/evening-star/1353/\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Glens Falls Post-Star\n",
    "Lima News"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
