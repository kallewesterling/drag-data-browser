{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# First make YAML from dataset\n",
    "\n",
    "# Then maybe use jinja or something to render as HTML\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "\n",
    "YEAR_RANGE = (1900, 1950)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def remove(row):\n",
    "    try:\n",
    "        date = dt.strptime(row.Date, '%Y-%m-%d')\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    if YEAR_RANGE and date.year >= YEAR_RANGE[0] and date.year <= YEAR_RANGE[1]:\n",
    "        pass # in the range!\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    if row['Exclude from visualization'] or row['Unsure whether drag artist']:\n",
    "        return True\n",
    "    \n",
    "    no_city = row['City'] == ''\n",
    "    no_performer = row['Performer'] == ''\n",
    "    no_venue = row['Venue'] == ''\n",
    "    unnamed_performer = 'unnamed' in row['Performer'].lower()\n",
    "    \n",
    "    if no_city and no_performer and no_venue:\n",
    "        return True\n",
    "    \n",
    "    if unnamed_performer:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def extract_addresses_dict(normalized_df):\n",
    "    addresses = {}\n",
    "    rows_with_addresses = normalized_df[normalized_df['Address']!='']\n",
    "    warnings = []\n",
    "    for x in zip(rows_with_addresses['Date'], rows_with_addresses['Source'], rows_with_addresses['Venue'], rows_with_addresses['Address']):\n",
    "        date, source, venue, address = x\n",
    "        if venue == '':\n",
    "            warnings.append(address)\n",
    "        else:\n",
    "            if not venue in addresses:\n",
    "                addresses[venue] = {}\n",
    "            if not source in addresses[venue]:\n",
    "                addresses[venue][source] = address\n",
    "    if len(warnings):\n",
    "        print(f'Warning: {len(warnings)} Venues with no names have addresses:')\n",
    "        print('- ' + '- '.join(warnings))\n",
    "\n",
    "    return addresses\n",
    "\n",
    "def reverse_comment_dict(comment_dict):\n",
    "    comments_reverse = {}\n",
    "    for performer, comments in comment_dict.items():\n",
    "        if not performer in comments_reverse:\n",
    "            comments_reverse[performer] = {}\n",
    "        for source, comment in comments.items():\n",
    "            if not comment in comments_reverse[performer]:\n",
    "                comments_reverse[performer][comment] = []\n",
    "            comments_reverse[performer][comment].append(source)\n",
    "    return comments_reverse\n",
    "        \n",
    "def get_comments(df, comment_field='Comment on edge: revue', match_field='Revue', transform=None):\n",
    "    comments = {}\n",
    "    rows_with_comments = df[df[comment_field]!='']\n",
    "    warnings = []\n",
    "    for x in zip(rows_with_comments['Date'], rows_with_comments['Source'], rows_with_comments[match_field], rows_with_comments[comment_field]):\n",
    "        date, source, match, comment = x\n",
    "        comment = str(comment).strip()\n",
    "        if transform:\n",
    "            comment = transform(comment)\n",
    "        if match == '':\n",
    "            warnings.append(str(comment)[:40]+'...')\n",
    "        else:\n",
    "            if not match in comments:\n",
    "                comments[match] = {}\n",
    "            if not source in comments[match]:\n",
    "                comments[match][source] = comment\n",
    "    if len(warnings):\n",
    "        print(f'Warning: {len(warnings)} mentions in `{comment_field}` with no value have comments:')\n",
    "        print('- ' + '\\n- '.join(warnings))\n",
    "\n",
    "    return comments\n",
    "\n",
    "def get_revue_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on edge: revue', 'Revue')\n",
    "\n",
    "def get_performer_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on node: performer', 'Performer')\n",
    "\n",
    "def get_venue_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on node: venue', 'Venue')\n",
    "\n",
    "def get_city_comments_dict(df):\n",
    "    return get_comments(df, 'Comment on node: city', 'City')\n",
    "\n",
    "def get_true_value(row, type):\n",
    "    if type == 'source':\n",
    "        if row['Source clean'] != '':\n",
    "            return row['Source clean']\n",
    "        return row['Source']\n",
    "    if type == 'performer':\n",
    "        if row['Normalized performer'] != '':\n",
    "            return row['Normalized performer']\n",
    "        if row['Performer first-name'] != '' and row['Performer last-name'] != '':\n",
    "            return row['Normalized performer']\n",
    "        return row['Performer']\n",
    "    if type == 'city':\n",
    "        if row['Normalized City'] != '':\n",
    "            return row['Normalized City']\n",
    "        return row['City']\n",
    "    if type == 'revue':\n",
    "        if row['Normalized Revue Name'] != '':\n",
    "            return row['Normalized Revue Name']\n",
    "        return row['Revue name']\n",
    "    if type == 'venue':\n",
    "        if row['Normalized Venue'] != '':\n",
    "            return row['Normalized Venue']\n",
    "        return row['Venue']\n",
    "    raise NotImplementedError(f'type `{type}` is not yet implemented')\n",
    "\n",
    "def find_ref(row, eima=True):\n",
    "    source = row['Source']\n",
    "    source += ' ' + row['EIMA']\n",
    "    source += ' ' + row['Search (newspapers.com)']\n",
    "    source += ' ' + row['Source clean']\n",
    "    \n",
    "    is_eima = 'eima' in source.lower() or 'variety' in source.lower() or 'billboard' in source.lower()\n",
    "    has_ref = re.search(r'(\\d{7,10})', source)\n",
    "    refs = list(set(re.findall(r'(\\d{7,10})', source)))\n",
    "    if has_ref and eima and is_eima:\n",
    "        return '|'.join(refs)\n",
    "    \n",
    "    if has_ref and not eima and not is_eima:\n",
    "        return '|'.join(refs)\n",
    "\n",
    "    return ''\n",
    "    \n",
    "\n",
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT0E0Y7txIa2pfBuusA1cd8X5OVhQ_D0qZC8D40KhTU3xB7McsPR2kuB7GH6ncmNT3nfjEYGbscOPp0/pub?gid=0&single=true&output=csv')\n",
    "df = df.fillna('')\n",
    "df = df.replace('—', '')\n",
    "df = df.replace('—*', '')\n",
    "\n",
    "# First, set up our references to EIMA and newspapers.com\n",
    "df['EIMA'] = df.apply(lambda row: find_ref(row), axis=1)\n",
    "df['Newspapers.com'] = df.apply(lambda row: find_ref(row, False), axis=1)\n",
    "\n",
    "# Normalize dataframe\n",
    "df['Source'] = df.apply(lambda row: get_true_value(row, 'source'), axis=1)\n",
    "df['Venue'] = df.apply(lambda row: get_true_value(row, 'venue'), axis=1)\n",
    "df['Performer'] = df.apply(lambda row: get_true_value(row, 'performer'), axis=1)\n",
    "df['City'] = df.apply(lambda row: get_true_value(row, 'city'), axis=1)\n",
    "df['Revue'] = df.apply(lambda row: get_true_value(row, 'revue'), axis=1)\n",
    "\n",
    "# Extract \"node\" information\n",
    "addresses = extract_addresses_dict(df)\n",
    "revue_comments = get_revue_comments_dict(df)\n",
    "performer_comments = get_performer_comments_dict(df)\n",
    "venue_comments = get_venue_comments_dict(df)\n",
    "city_comments = get_city_comments_dict(df)\n",
    "edge_comments = get_comments(df, 'Edge Comment', 'Source')\n",
    "legal_names = get_comments(df, 'Legal name', 'Performer')\n",
    "ages = get_comments(df, 'Alleged age', 'Performer', lambda x: int(float(x)))\n",
    "birth_years = get_comments(df, 'Assumed birth year', 'Performer', lambda x: int(float(x)))\n",
    "eima_links = get_comments(df, 'EIMA', 'Source')\n",
    "newspaper_links = get_comments(df, 'Newspapers.com', 'Source')\n",
    "\n",
    "# Edge booleans\n",
    "blackface_performers = get_comments(df, 'Blackface', 'Performer', lambda x: bool(x))\n",
    "sepia_performers = get_comments(df, 'Sepia', 'Performer', lambda x: bool(x))\n",
    "fan_dance_performers = get_comments(df, 'Fan dancer/Sally Rand', 'Performer', lambda x: bool(x))\n",
    "exotic_dancers = get_comments(df, 'Exotic/erotic/oriental dancer/Gypsy', 'Performer', lambda x: bool(x))\n",
    "has_image = get_comments(df, 'Has image', 'Performer', lambda x: bool(x))\n",
    "\n",
    "# Drop filtered data\n",
    "df['remove'] = df.apply(lambda row: remove(row), axis=1)\n",
    "df = df.drop(df[df['remove']==True].index)\n",
    "\n",
    "# Drop columns\n",
    "df = df.drop(['Category', 'EIMA', 'Newspapers.com', 'Search (newspapers.com)', 'Blackface', 'Sepia', 'Fan dancer/Sally Rand', 'Exotic/erotic/oriental dancer/Gypsy', 'Has image', 'Legal name', 'Alleged age', 'Assumed birth year', 'Search (fulton)', 'Imported from former archive', 'Edge Comment', 'Comment on node: performer', 'Comment on node: venue', 'Comment on node: city', 'Comment on edge: revue', 'Exclude from visualization', 'Address', 'Unsure whether drag artist', 'Source clean', 'Normalized performer', 'Performer first-name', 'Performer last-name', 'Normalized Venue', 'Normalized City', 'Normalized Revue Name', 'Revue name', 'remove'], axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: 1 Venues with no names have addresses:\n",
      "- 925 East Main Street\n",
      "Warning: 105 mentions in `Comment on edge: revue` with no value have comments:\n",
      "- \"A treat will be offered to the patrons ...\n",
      "- Touring circus, LaTour was with them las...\n",
      "- \"About September 15, Barnett Hyman will ...\n",
      "- \"Direct from K-9 Club, Chicago\"...\n",
      "- \"Direct from K-9 Club, Chicago\"...\n",
      "- \"Direct from K-9 Club, Chicago\"...\n",
      "- \"Direct from K-9 Club, Chicago\"...\n",
      "- \"Direct from K-9 Club, Chicago\"...\n",
      "- \"Sensational Floor Show\"...\n",
      "- \"Sensational Floor Show\"...\n",
      "- featuring \"Several Female Impersonators\"...\n",
      "- featuring \"Several Female Impersonators\"...\n",
      "- featuring \"Several Female Impersonators\"...\n",
      "- \"Here a corking good floor show is prese...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- Paris-Harlem Nite club and ball room, \"s...\n",
      "- \"Opening Wednesday Nite, July 3rd\", \"Pre...\n",
      "- Direct to The Blue Room from Club Richma...\n",
      "- \"Opening Wednesday Nite, July 3rd\", \"Pre...\n",
      "- Direct to The Blue Room from Club Richma...\n",
      "- \"Opening Wednesday Nite, July 3rd\", \"Pre...\n",
      "- Direct to The Blue Room from Club Richma...\n",
      "- \"Opening Wednesday Nite, July 3rd\", \"Pre...\n",
      "- Direct to The Blue Room from Club Richma...\n",
      "- \"Gala Floor Show\"...\n",
      "- \"Where Boys Will Be Girls\" \"8 Big Acts\"...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"Wednesday night is a gay night . . . wi...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"3 Complete Floor Shows Nightly\"...\n",
      "- \"for another week . . . Supporting him a...\n",
      "- Barrows is the producer of the unique re...\n",
      "- \"Maier and his plain-clothes men watched...\n",
      "- \"Maier and his plain-clothes men watched...\n",
      "- \"Female Impersonator Revue\"...\n",
      "- \"Female Impersonator Revue\"...\n",
      "- \"Female Impersonator Revue\"...\n",
      "- \"Female Impersonator Revue\"...\n",
      "- \"Female Impersonator Revue\"...\n",
      "- \"Joy Week\" - \"World's Greatest Female Im...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"Big Floor Show\", \"Positively the Funnie...\n",
      "- \"12th week at Club Picadilly, Baltimore\"...\n",
      "- \"floor show extraordinary for one week o...\n",
      "- \"floor show extraordinary for one week o...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"Featuring Three Stellar Female Imperson...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"Line of Girls, 'The Four Rhythmettes'\"...\n",
      "- \"Line of Girls, 'The Four Rhythmettes'\"...\n",
      "- \"Line of Girls, 'The Four Rhythmettes'\"...\n",
      "- \"Line of Girls, 'The Four Rhythmettes'\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"Line of Girls, 'The Four Rhythmettes'\"...\n",
      "- \"Line of Girls, 'The Four Rhythmettes'\"...\n",
      "- \"San Francisco's Sensational Show\"...\n",
      "- \"Female impersonators, 4 shows. Hearties...\n",
      "- \"Female impersonators, 4 shows. Hearties...\n",
      "- \"Female impersonators, 4 shows. Hearties...\n",
      "- \"HELD OVER BY POPULAR DEMAND!\", \"Gay . ....\n",
      "- \"Star Studded Revue of Nationally Famed ...\n",
      "- \"Star Studded Revue of Nationally Famed ...\n",
      "- \"Star Studded Revue of Nationally Famed ...\n",
      "- \"Star Studded Revue of Nationally Famed ...\n",
      "- \"Star Studded Revue of Nationally Famed ...\n",
      "- \"Star Studded Revue of Nationally Famed ...\n",
      "- touring circus...\n",
      "- touring circus...\n",
      "- touring circus...\n",
      "- show closed down \"shortly after it opene...\n",
      "Warning: 5 mentions in `Comment on node: performer` with no value have comments:\n",
      "- \"Court attendants, principals at the hea...\n",
      "- \"Female Impersonator Direct from DANTE'S...\n",
      "- \"The Torch Goes Gay\"...\n",
      "- One of the sepia female impersonators in...\n",
      "- Inferring that Lyle Mack was present sin...\n",
      "Warning: 3 mentions in `Comment on node: venue` with no value have comments:\n",
      "- \"at Terrace Gardens . . . after finishin...\n",
      "- El Paso Shriners' sidewalk circus...\n",
      "- \"Danny Brown's all-male revue jumped to ...\n",
      "Warning: 1 mentions in `Comment on node: city` with no value have comments:\n",
      "- \"A ban on female impersonation, or vice ...\n",
      "Warning: 1 mentions in `Legal name` with no value have comments:\n",
      "- William Harris...\n",
      "Warning: 1 mentions in `Exotic/erotic/oriental dancer/Gypsy` with no value have comments:\n",
      "- True...\n",
      "Warning: 1 mentions in `Has image` with no value have comments:\n",
      "- True...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Time to render some files\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from slugify import slugify\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def keyshift(dictionary, key, diff):\n",
    "    if key in dictionary:\n",
    "        token = object()\n",
    "        keys = [token]*(diff*-1) + sorted(dictionary) + [token]*diff\n",
    "        newkey = keys[keys.index(key)+diff]\n",
    "        if newkey is token:\n",
    "            return None\n",
    "        else:\n",
    "            return newkey\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def slugify_column(df, column='Performer'):\n",
    "    if not column == 'Performer':\n",
    "        all_values = list(sorted(set([x for x in df[column] if x and not x.startswith('—')])))\n",
    "    else:\n",
    "        all_values = list(sorted(set([x for x in df[column] if x]))) # we have to include the ones that start with — here\n",
    "    values_dict = {}\n",
    "    for value in all_values:\n",
    "        done = False\n",
    "        i = 0\n",
    "        while not done:\n",
    "            if i == 0:\n",
    "                if not slugify(value) in values_dict:\n",
    "                    values_dict[slugify(value)] = value\n",
    "                    done = True\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                print('Warning: Multiple values with the same value. This should not happen:', value)\n",
    "                if not f'{slugify(value)}-{i}' in values_dict:\n",
    "                    values_dict[f'{slugify(value)}-{i}'] = value\n",
    "                    done = True\n",
    "                else:\n",
    "                    i += 1\n",
    "    return {v: k for k, v in values_dict.items()} # reversed\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_venue_slug(venue):\n",
    "    return ALL_VENUES[venue]\n",
    "\n",
    "def get_performer_slug(performer):\n",
    "    return ALL_PERFORMERS[performer]\n",
    "\n",
    "\n",
    "def make_calendar(df):\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    calendar = OrderedDict()\n",
    "\n",
    "    years = [pd.to_datetime(x).year for x in df.Date]\n",
    "    min_year = min(years)\n",
    "    max_year = max(years)\n",
    "\n",
    "    years = range(min_year, max_year+1)\n",
    "    months = range(1,13)\n",
    "    for year in years:\n",
    "        if not year in calendar:\n",
    "            calendar[year] = OrderedDict()\n",
    "        for month in months:\n",
    "            # 31 = jan, mar, may, jul, aug, oct, dec\n",
    "            # 30 = apr, jun, sep, nov\n",
    "            # 28 = feb\n",
    "            if not month in calendar[year]:\n",
    "                calendar[year][month] = OrderedDict()\n",
    "            if month == 2:\n",
    "                days = range(1,30) #adding the 29th day despite it not always existing\n",
    "            elif month in [4, 6, 9, 11]:\n",
    "                days = range(1,31)\n",
    "            elif month in [1,3,5,7,8,10,12]:\n",
    "                days = range(1,32)\n",
    "            else:\n",
    "                raise RuntimeError('error')\n",
    "\n",
    "            for day in days:\n",
    "                if not day in calendar[year][month]:\n",
    "                    calendar[year][month][day] = 0\n",
    "\n",
    "    for date in [pd.to_datetime(date) for date in df.sort_values('Date').Date]:\n",
    "        calendar[date.year][date.month][date.day] += 1\n",
    "        \n",
    "    return calendar\n",
    "\n",
    "\n",
    "TEMPLATE_DIR = '/Users/kallewesterling/Repositories/kallewesterling/dissertation/drag-data-browser/templates/'\n",
    "OUTPUT_DIR = '/Users/kallewesterling/Repositories/kallewesterling/dissertation/drag-data-browser/docs/'\n",
    "DATASET_OUTPUT_DIR = OUTPUT_DIR + 'dataset/'\n",
    "\n",
    "\n",
    "e = Environment(loader=FileSystemLoader(TEMPLATE_DIR))\n",
    "\n",
    "ALL_YEARS = list(range(YEAR_RANGE[0], YEAR_RANGE[1]))\n",
    "ALL_PERFORMERS = slugify_column(df, 'Performer')\n",
    "ALL_VENUES = slugify_column(df, 'Unique venue')\n",
    "ALL_CITIES = slugify_column(df, 'City')\n",
    "\n",
    "e.globals['slugify'] = slugify\n",
    "e.globals['get_venue_slug'] = get_venue_slug\n",
    "e.globals['get_performer_slug'] = get_performer_slug\n",
    "e.globals['ALL_YEARS'] = ALL_YEARS\n",
    "e.globals['ALL_PERFORMERS'] = ALL_PERFORMERS\n",
    "e.globals['ALL_VENUES'] = ALL_VENUES\n",
    "e.globals['ALL_CITIES'] = ALL_CITIES\n",
    "e.globals['PERFORMER_COMMENTS'] = reverse_comment_dict(performer_comments)\n",
    "e.globals['VENUE_COMMENTS'] = reverse_comment_dict(venue_comments)\n",
    "e.globals['CITY_COMMENTS'] = reverse_comment_dict(city_comments)\n",
    "e.globals['NEWSPAPERS_LINKS'] = newspaper_links\n",
    "e.globals['EIMA_LINKS'] = eima_links\n",
    "e.globals['CALENDAR'] = make_calendar(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "e.globals['str'] = str"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_name_mapping(df):\n",
    "    from nameparser import HumanName\n",
    "    _ = {}\n",
    "    return {x: (HumanName(x).first, HumanName(x).middle, HumanName(x).last) for x in df.Performer}\n",
    "\n",
    "e.globals['NAME_MAPPING'] = get_name_mapping(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "mappings = {\n",
    "    ('Albert', 'Henry', 'Cook'): ['Albert Henry', 'Cook'],\n",
    "    ('Baby', 'Jan', 'Ray'): ['Baby Jan', 'Ray'],\n",
    "    ('Edward', 'Albert', 'Crawford'): ['Edward Albert', 'Crawford'],\n",
    "    ('Frank', 'Barrett', 'Carman'): ['Frank', 'Barrett Carman'],\n",
    "    ('J.', 'John', 'Howard'): ['J. John', 'Howard'],\n",
    "    ('James', 'Ernest', 'Allen'): ['James Ernest', 'Allen'],\n",
    "    ('La', 'Belle', 'Rose'): ['La Belle', 'Rose'],\n",
    "    ('Nina', 'Mae', 'McKinney'): ['Nina Mae', 'McKinney'],\n",
    "    ('Nora', 'Corona', 'Hancock'): ['Nora', 'Corona Hancock'],\n",
    "    ('Ray', 'Erline', 'Garrison'): ['Ray', 'Erline Garrison'],\n",
    "    ('Richard', 'Snooks', 'Davis'): ['Richard', 'Snooks Davis'],\n",
    "    ('Sepia', 'Gloria', 'Swanson'): ['Gloria', 'Swanson'],\n",
    "    ('Sepia', 'Greta', 'Garbo'): ['Greta', 'Garbo'],\n",
    "    ('Sepia', 'Mae', 'West'): ['Sepia Mae', 'West'],\n",
    "    ('Sweet', 'Mama', 'Sue'): ['Sweet Mama Sue'],\n",
    "    ('Thompson', 'Twin', '1'): ['Thompson Twins'],\n",
    "    ('Thompson', 'Twin', '2'): ['Thompson Twins'],\n",
    "    ('Titanic', 'Kit', 'Russell'): ['Kit', 'Russell'],\n",
    "    ('William', 'Lee', 'Becker'): ['William', 'Lee Becker'],\n",
    "    ('Doran,', 'West,', 'and', 'Doran'): ['Doran, West, and Doran'],\n",
    "    ('Elsie', 'the', 'Cobra', 'Woman'): ['Elsie the Cobra Woman'],\n",
    "    ('F', '&', 'G', 'Doran'): ['F. and G.', 'Doran'],\n",
    "    ('Lynn', 'and', 'De', 'Marco'): ['Lynn and De Marco'],\n",
    "    ('May', 'West', 'of', 'the', 'East'): ['Sepia Mae', 'West'],\n",
    "    ('Mother', 'Smother/Sepia', 'Marlene', 'Dietrich'): ['Marlene', 'Dietrich']\n",
    "}\n",
    "\n",
    "def make_performer_clippings(list_of_performers):\n",
    "    _ = {}\n",
    "    \n",
    "    def get_comment(name):\n",
    "        if FILE_COMMENT.search(name):\n",
    "            return FILE_COMMENT.search(name).groups()[1]\n",
    "        return ''\n",
    "\n",
    "    import glob\n",
    "    ARCHIVE_PNG_PATHS = [x.lower() for x in glob.glob('/Volumes/GoogleDrive/My Drive/Ongoing Projects/Dissertation - Archive/- My own clippings and photos/**/*.png', recursive=True)]\n",
    "    ARCHIVE_FOLDERS = [x.lower() for x in glob.glob('/Volumes/GoogleDrive/My Drive/Ongoing Projects/Dissertation - Archive/- My own clippings and photos/*')]\n",
    "    FILE_COMMENT = re.compile(r'(.*) ?\\[(.*)\\]')\n",
    "\n",
    "    for performer in list_of_performers:\n",
    "        found = False\n",
    "\n",
    "        if not performer:\n",
    "            continue\n",
    "\n",
    "        names = performer.split(' ')\n",
    "        if len(names) == 3:\n",
    "            if names[1] == 'La' or names[1] == 'Le' or names[1] == 'De' or names[1] == 'Del' or names[1] == 'St.' or names[1] == 'Van' or names[1] == 'Val' or names[1] == 'the':\n",
    "                names = [f'{names[0]}', f'{names[1]} {names[2]}']\n",
    "            elif names[1] == '&' or names[1] == 'and':\n",
    "                names = [f'{names[0]} {names[1]} {names[2]}']\n",
    "            elif len(names[0]) < 3 and len(names[1]) < 3:\n",
    "                names = [names[2], f'{names[0]} {names[1]}']\n",
    "            elif len(names[1]) < 3:\n",
    "                names = [f'{names[0]} {names[1]}', f'{names[2]}']\n",
    "            elif names[0] == 'The':\n",
    "                names = [f'{names[0]} {names[1]}', f'{names[2]}']\n",
    "            elif names[0] == 'Miss':\n",
    "                names = [f'{names[0]}', f'{names[1]}']\n",
    "            elif names[1].startswith('\"') or names[1].startswith('('):\n",
    "                names = [f'{names[1]}', f'{names[2]}']\n",
    "            else:\n",
    "                if not mappings.get(tuple(names)):\n",
    "                    print(names)\n",
    "                else:\n",
    "                    names = mappings.get(tuple(names))\n",
    "        elif len(names) > 3:\n",
    "            if not mappings.get(tuple(names)):\n",
    "                print(names)\n",
    "            else:\n",
    "                names = mappings.get(tuple(names))\n",
    "\n",
    "        names = [x.lower() for x in names]\n",
    "        \n",
    "        if len(names) == 2:\n",
    "            search = [x for x in ARCHIVE_FOLDERS if (f'{names[1]}, {names[0]}' in x or f'{names[0]} {names[1]}' in x) and 'performer' in get_comment(x)]\n",
    "            if len(search) == 1:\n",
    "                found = search[0]\n",
    "            else:\n",
    "                pass # print(f'{names[1]}, {names[0]}', search)\n",
    "                \n",
    "        elif len(names) == 1:\n",
    "            search = [x for x in ARCHIVE_FOLDERS if Path(x).stem.startswith(names[0])]\n",
    "            if len(search) == 1:\n",
    "                found = search[0]\n",
    "            else:\n",
    "                pass # print(names, search)\n",
    "        elif len(names) == 3:\n",
    "            search = [x for x in ARCHIVE_FOLDERS if (f'{names[2]}, {names[0]} {names[1]}' in x or f'{names[0]} {names[1]}' in x) and 'performer' in get_comment(x)]\n",
    "            if len(search) == 1:\n",
    "                found = search[0]\n",
    "            else:\n",
    "                pass # print(f'{names[2]}, {names[0]} {names[1]}', search)\n",
    "\n",
    "        if found:\n",
    "            if not 'performer' in get_comment(Path(found).name) and not 'producer' in get_comment(Path(found).name):\n",
    "                print(f'Warning: Found matching clippings folder with wrong name, so decoupling: {performer} ≠ {Path(found).name}')\n",
    "                found = False # if not a performer or producer\n",
    "        else:\n",
    "            print(f'Warning: {performer} does not exist in clippings')\n",
    "            found = ''\n",
    "            \n",
    "        _[performer] = found\n",
    "    \n",
    "    return _\n",
    "\n",
    "\n",
    "\n",
    "e.globals['PERFORMER_CLIPPINGS'] = make_performer_clippings([x for x, _ in df.groupby('Performer') if x])\n",
    "e.globals['PERFORMER_CLIPPINGS'] = {x:y for x,y in e.globals['PERFORMER_CLIPPINGS'].items() if y}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: Adrian Norris does not exist in clippings\n",
      "Warning: Adrienne does not exist in clippings\n",
      "Warning: Al Benson does not exist in clippings\n",
      "Warning: Al DeMarco does not exist in clippings\n",
      "Warning: Al Garbell does not exist in clippings\n",
      "Warning: Al Lucas does not exist in clippings\n",
      "Warning: Al Ray does not exist in clippings\n",
      "Warning: Al Sterling does not exist in clippings\n",
      "Warning: Alan Gray does not exist in clippings\n",
      "Warning: Albert Henry Cook does not exist in clippings\n",
      "Warning: Albert Hogue does not exist in clippings\n",
      "Warning: Alfred Carmen does not exist in clippings\n",
      "Warning: Alice Rydner does not exist in clippings\n",
      "Warning: Alice White does not exist in clippings\n",
      "Warning: Allan Cook does not exist in clippings\n",
      "Warning: Allen Carl does not exist in clippings\n",
      "Warning: Andrew Tribble does not exist in clippings\n",
      "Warning: Andy Cliff does not exist in clippings\n",
      "Warning: Anthony DiMeo does not exist in clippings\n",
      "Warning: Arica Wild does not exist in clippings\n",
      "Warning: Art Bernard does not exist in clippings\n",
      "Warning: Art West does not exist in clippings\n",
      "Warning: Arthur Budd does not exist in clippings\n",
      "Warning: Arthur G. West does not exist in clippings\n",
      "Warning: Arthur La Delle does not exist in clippings\n",
      "Warning: Arthur Verity does not exist in clippings\n",
      "Warning: Arthur Wilson does not exist in clippings\n",
      "Warning: Arvin Giese does not exist in clippings\n",
      "Warning: Au Sing does not exist in clippings\n",
      "Warning: Bab Garrison does not exist in clippings\n",
      "Warning: Babe Allen does not exist in clippings\n",
      "Warning: Babe Baker does not exist in clippings\n",
      "Warning: Baby Jan Ray does not exist in clippings\n",
      "Warning: Beatrice Howle does not exist in clippings\n",
      "Warning: Bel Ager does not exist in clippings\n",
      "Warning: Benny Pauly does not exist in clippings\n",
      "Warning: Bernie Salin does not exist in clippings\n",
      "Warning: Bert Kelley does not exist in clippings\n",
      "Warning: Bert Sherry does not exist in clippings\n",
      "Warning: Bert Wheeler does not exist in clippings\n",
      "Warning: Bertie Bierman does not exist in clippings\n",
      "Warning: Betty Lee does not exist in clippings\n",
      "Warning: Bill Jones does not exist in clippings\n",
      "Warning: Bill Kennedy does not exist in clippings\n",
      "Warning: Billie Brannon does not exist in clippings\n",
      "Warning: Billie Dale does not exist in clippings\n",
      "Warning: Billie Davis does not exist in clippings\n",
      "Warning: Billie Dove does not exist in clippings\n",
      "Warning: Billie Kemp does not exist in clippings\n",
      "Warning: Billie Marsh does not exist in clippings\n",
      "Warning: Billie McAllister does not exist in clippings\n",
      "Warning: Billie Russell does not exist in clippings\n",
      "Warning: Billy does not exist in clippings\n",
      "Warning: Billy \"Senorita\" Herrera does not exist in clippings\n",
      "Warning: Billy Ardelle does not exist in clippings\n",
      "Warning: Billy Byrne does not exist in clippings\n",
      "Warning: Billy Earle does not exist in clippings\n",
      "Warning: Billy Hayes does not exist in clippings\n",
      "Warning: Billy Irwin does not exist in clippings\n",
      "Warning: Billy Joy does not exist in clippings\n",
      "Warning: Billy Kamp does not exist in clippings\n",
      "Warning: Billy Kent does not exist in clippings\n",
      "Warning: Billy Lamont does not exist in clippings\n",
      "Warning: Billy Lynn does not exist in clippings\n",
      "Warning: Billy Nichols does not exist in clippings\n",
      "Warning: Billy O'Brien does not exist in clippings\n",
      "Warning: Billy Pinnell does not exist in clippings\n",
      "Warning: Billy Reed does not exist in clippings\n",
      "Warning: Billy Richards does not exist in clippings\n",
      "Warning: Billy Turner does not exist in clippings\n",
      "Warning: Billy West does not exist in clippings\n",
      "Warning: Blackie Dennis does not exist in clippings\n",
      "Warning: Bob Mack does not exist in clippings\n",
      "Warning: Bobbie Bell does not exist in clippings\n",
      "Warning: Bobbie Clark does not exist in clippings\n",
      "Warning: Bobbie Davis does not exist in clippings\n",
      "Warning: Bobbie Grant does not exist in clippings\n",
      "Warning: Bobbie Kaye does not exist in clippings\n",
      "Warning: Bobbie Macklin does not exist in clippings\n",
      "Warning: Bobbie Marlowe does not exist in clippings\n",
      "Warning: Bobbie Ray does not exist in clippings\n",
      "Warning: Bobbie Rowland does not exist in clippings\n",
      "Warning: Bobby Allen does not exist in clippings\n",
      "Warning: Bobby Brennan does not exist in clippings\n",
      "Warning: Bobby Cummins does not exist in clippings\n",
      "Warning: Bobby Ferguson does not exist in clippings\n",
      "Warning: Bobby Gay does not exist in clippings\n",
      "Warning: Bobby Gordon does not exist in clippings\n",
      "Warning: Bobby Grant does not exist in clippings\n",
      "Warning: Bobby Hayes does not exist in clippings\n",
      "Warning: Bobby Johnson does not exist in clippings\n",
      "Warning: Bobby Jones does not exist in clippings\n",
      "Warning: Bobby Kork does not exist in clippings\n",
      "Warning: Bobby Lane does not exist in clippings\n",
      "Warning: Bobby Leonard does not exist in clippings\n",
      "Warning: Bobby Mason does not exist in clippings\n",
      "Warning: Bobby Mitchell does not exist in clippings\n",
      "Warning: Bobby Norman does not exist in clippings\n",
      "Warning: Bobby Royce does not exist in clippings\n",
      "Warning: Bobby Stevens does not exist in clippings\n",
      "Warning: Bobby Sullivan does not exist in clippings\n",
      "Warning: Bobby Trent does not exist in clippings\n",
      "Warning: Bobby Verrill does not exist in clippings\n",
      "Warning: Bohannan does not exist in clippings\n",
      "Warning: Bonnie does not exist in clippings\n",
      "Warning: Bonnie Clark does not exist in clippings\n",
      "Warning: Bonnie Lee does not exist in clippings\n",
      "Warning: Brannan Fernandez does not exist in clippings\n",
      "Warning: Brooks Twins does not exist in clippings\n",
      "Warning: Bud Byron does not exist in clippings\n",
      "Warning: Bud Hart does not exist in clippings\n",
      "Warning: Buddy Rokahr does not exist in clippings\n",
      "Warning: Bunny does not exist in clippings\n",
      "Warning: Bunny Daye does not exist in clippings\n",
      "Warning: Bunny Dorne does not exist in clippings\n",
      "Warning: Buster Brant does not exist in clippings\n",
      "Warning: Buster Hewitt does not exist in clippings\n",
      "Warning: Cardie Woodie does not exist in clippings\n",
      "Warning: Carl Clewis does not exist in clippings\n",
      "Warning: Carl Nixon does not exist in clippings\n",
      "Warning: Carll Morgan does not exist in clippings\n",
      "Warning: Carlo Levins does not exist in clippings\n",
      "Warning: Carlos J. Henderson does not exist in clippings\n",
      "Warning: Carmencita does not exist in clippings\n",
      "Warning: Carol Lee does not exist in clippings\n",
      "Warning: Carol Mack does not exist in clippings\n",
      "Warning: Carrol Thomas does not exist in clippings\n",
      "Warning: Carroll Davis does not exist in clippings\n",
      "Warning: Carroll Wallace does not exist in clippings\n",
      "Warning: Cecil Mason does not exist in clippings\n",
      "Warning: Found matching clippings folder with wrong name, so decoupling: Champagne ≠ champagne safari [group; sweden; helsingborg]\n",
      "Warning: Charles Alexander does not exist in clippings\n",
      "Warning: Charles Ander does not exist in clippings\n",
      "Warning: Charles Bell does not exist in clippings\n",
      "Warning: Charles Davis does not exist in clippings\n",
      "Warning: Charles Moore does not exist in clippings\n",
      "Warning: Charles Wilhelm does not exist in clippings\n",
      "Warning: Charley Anderson does not exist in clippings\n",
      "Warning: Charley Brugnone does not exist in clippings\n",
      "Warning: Chick Chandler does not exist in clippings\n",
      "Warning: Chicki Forrest does not exist in clippings\n",
      "Warning: Chickie Mears does not exist in clippings\n",
      "Warning: Chris Bailey does not exist in clippings\n",
      "Warning: Chubby Smith does not exist in clippings\n",
      "Warning: Chuck Marvin does not exist in clippings\n",
      "Warning: Clara Bow does not exist in clippings\n",
      "Warning: Clare St. Clair does not exist in clippings\n",
      "Warning: Clarence Long does not exist in clippings\n",
      "Warning: Clarence Spicer does not exist in clippings\n",
      "Warning: Clarence Thomas does not exist in clippings\n",
      "Warning: Clarence Weems does not exist in clippings\n",
      "Warning: Clarenz Henderson does not exist in clippings\n",
      "Warning: Claudetener does not exist in clippings\n",
      "Warning: Cleo Renee does not exist in clippings\n",
      "Warning: Cleo Stafford does not exist in clippings\n",
      "Warning: Cliff LaVerne does not exist in clippings\n",
      "Warning: Clinton De Forrest does not exist in clippings\n",
      "Warning: Connie does not exist in clippings\n",
      "Warning: Connie Miller does not exist in clippings\n",
      "Warning: Connie Walsh does not exist in clippings\n",
      "Warning: Conrad Fitzgerald does not exist in clippings\n",
      "Warning: Daisy Devoe does not exist in clippings\n",
      "Warning: Daisy Navarro does not exist in clippings\n",
      "Warning: Dan Carson does not exist in clippings\n",
      "Warning: Danny Brown does not exist in clippings\n",
      "Warning: Danny King does not exist in clippings\n",
      "Warning: Danny Lee does not exist in clippings\n",
      "Warning: Darryl? Gilbert? does not exist in clippings\n",
      "Warning: Dave Gold does not exist in clippings\n",
      "Warning: Dave Shaw does not exist in clippings\n",
      "Warning: David J. Doyle does not exist in clippings\n",
      "Warning: Davy Lee does not exist in clippings\n",
      "Warning: Dawn Sis does not exist in clippings\n",
      "Warning: Day Sherry does not exist in clippings\n",
      "Warning: Deanna Durbin does not exist in clippings\n",
      "Warning: Dee Liddell does not exist in clippings\n",
      "Warning: Del Dreer does not exist in clippings\n",
      "Warning: Del Raye does not exist in clippings\n",
      "Warning: Delores Del Rio does not exist in clippings\n",
      "Warning: Dennis Griffin does not exist in clippings\n",
      "Warning: Dick Hastings does not exist in clippings\n",
      "Warning: Dick Lane does not exist in clippings\n",
      "Warning: Dick Ricardo does not exist in clippings\n",
      "Warning: Dickie Ray does not exist in clippings\n",
      "Warning: Dixie Day does not exist in clippings\n",
      "Warning: Dixie DeLane does not exist in clippings\n",
      "Warning: Dixie Dixon does not exist in clippings\n",
      "Warning: Dixie Jean does not exist in clippings\n",
      "Warning: Dixie Lee does not exist in clippings\n",
      "Warning: Dolly Levins does not exist in clippings\n",
      "Warning: Dolly O'Day does not exist in clippings\n",
      "Warning: Dom Tangee does not exist in clippings\n",
      "Warning: Don Holly does not exist in clippings\n",
      "Warning: Don Kenyard does not exist in clippings\n",
      "Warning: Don La Rue does not exist in clippings\n",
      "Warning: Don Rand does not exist in clippings\n",
      "Warning: Donald Grey does not exist in clippings\n",
      "Warning: Donna Glover does not exist in clippings\n",
      "Warning: Donnie Dawn does not exist in clippings\n",
      "Warning: Doris does not exist in clippings\n",
      "Warning: Doris (Dimples) White does not exist in clippings\n",
      "Warning: Dorothy Page does not exist in clippings\n",
      "Warning: Doyle Mack does not exist in clippings\n",
      "Warning: E. Russell does not exist in clippings\n",
      "Warning: E. Walter does not exist in clippings\n",
      "Warning: Earl Partello does not exist in clippings\n",
      "Warning: Ed-Na Link does not exist in clippings\n",
      "Warning: Eddie Adams does not exist in clippings\n",
      "Warning: Eddie Crawford does not exist in clippings\n",
      "Warning: Eddie Cushenberry does not exist in clippings\n",
      "Warning: Eddie Green does not exist in clippings\n",
      "Warning: Eddie Guertin does not exist in clippings\n",
      "Warning: Eddie La Rue does not exist in clippings\n",
      "Warning: Eddie Lee does not exist in clippings\n",
      "Warning: Eddie Morton does not exist in clippings\n",
      "Warning: Eddie Rogers does not exist in clippings\n",
      "Warning: Eddie White does not exist in clippings\n",
      "Warning: Edith Anderson does not exist in clippings\n",
      "Warning: Edmund Link does not exist in clippings\n",
      "Warning: Edna Leonard does not exist in clippings\n",
      "Warning: Edward Albert Crawford does not exist in clippings\n",
      "Warning: Edward Allworth does not exist in clippings\n",
      "Warning: Edward Collins does not exist in clippings\n",
      "Warning: Edward Delange does not exist in clippings\n",
      "Warning: Edward F. Dolan does not exist in clippings\n",
      "Warning: Edward Lerner does not exist in clippings\n",
      "Warning: Eli Madlof does not exist in clippings\n",
      "Warning: Elsie Day does not exist in clippings\n",
      "Warning: Elsie the Cobra Woman does not exist in clippings\n",
      "Warning: Enna Davison does not exist in clippings\n",
      "Warning: Ernest Davidson does not exist in clippings\n",
      "Warning: Etailook Hoy does not exist in clippings\n",
      "Warning: Eugene Ebol does not exist in clippings\n",
      "Warning: Evelyn West does not exist in clippings\n",
      "Warning: Farfariello does not exist in clippings\n",
      "Warning: Fay Elliot does not exist in clippings\n",
      "Warning: Ferne Proctor does not exist in clippings\n",
      "Warning: Fifi does not exist in clippings\n",
      "Warning: Flo Arden does not exist in clippings\n",
      "Warning: Florence King does not exist in clippings\n",
      "Warning: Floyd Savage does not exist in clippings\n",
      "Warning: Frances David does not exist in clippings\n",
      "Warning: Frances Dee does not exist in clippings\n",
      "Warning: Frances Dunn does not exist in clippings\n",
      "Warning: Frances Fay does not exist in clippings\n",
      "Warning: Frances Hall does not exist in clippings\n",
      "Warning: Frances La Verne does not exist in clippings\n",
      "Warning: Frances Lee does not exist in clippings\n",
      "Warning: Francis Bouche does not exist in clippings\n",
      "Warning: Francis Davis does not exist in clippings\n",
      "Warning: Francis Loite does not exist in clippings\n",
      "Warning: Francis Ritz does not exist in clippings\n",
      "Warning: Francis Russell does not exist in clippings\n",
      "Warning: Francis Stillman does not exist in clippings\n",
      "Warning: Francis Strom does not exist in clippings\n",
      "Warning: Frank Barrett Carman does not exist in clippings\n",
      "Warning: Frank Burns does not exist in clippings\n",
      "Warning: Frank Doran does not exist in clippings\n",
      "Warning: Frank E. Carroll does not exist in clippings\n",
      "Warning: Frank Keith does not exist in clippings\n",
      "Warning: Frank Perry does not exist in clippings\n",
      "Warning: Frank Tymm does not exist in clippings\n",
      "Warning: Frankie Gondone does not exist in clippings\n",
      "Warning: Frankie Huntsinger does not exist in clippings\n",
      "Warning: Fred Berrens does not exist in clippings\n",
      "Warning: Fred Moore does not exist in clippings\n",
      "Warning: Fred Munroe does not exist in clippings\n",
      "Warning: Fred Noll does not exist in clippings\n",
      "Warning: Freddie Phillips does not exist in clippings\n",
      "Warning: Freddie Wheeler does not exist in clippings\n",
      "Warning: Freddy Wheeler does not exist in clippings\n",
      "Warning: Fredricka does not exist in clippings\n",
      "Warning: Fritz Cantz does not exist in clippings\n",
      "Warning: Fritzie Feltz does not exist in clippings\n",
      "Warning: G. Doran does not exist in clippings\n",
      "Warning: Gabby Lee does not exist in clippings\n",
      "Warning: Gale Page does not exist in clippings\n",
      "Warning: Garry Teasdale does not exist in clippings\n",
      "Warning: Gary Edwards does not exist in clippings\n",
      "Warning: Gay Byerd does not exist in clippings\n",
      "Warning: Geane Ray does not exist in clippings\n",
      "Warning: Gene Abbott does not exist in clippings\n",
      "Warning: Gene Baye does not exist in clippings\n",
      "Warning: Gene Casali does not exist in clippings\n",
      "Warning: Gene Darling does not exist in clippings\n",
      "Warning: Gene Ford does not exist in clippings\n",
      "Warning: Gene Gordon does not exist in clippings\n",
      "Warning: Gene Jeanette does not exist in clippings\n",
      "Warning: Gene Kauffyn does not exist in clippings\n",
      "Warning: Gene Renee does not exist in clippings\n",
      "Warning: Gene Russell does not exist in clippings\n",
      "Warning: George Charles does not exist in clippings\n",
      "Warning: George Denny does not exist in clippings\n",
      "Warning: George Hayes does not exist in clippings\n",
      "Warning: George Kelly does not exist in clippings\n",
      "Warning: George McDowell does not exist in clippings\n",
      "Warning: George Oliver does not exist in clippings\n",
      "Warning: George Parker does not exist in clippings\n",
      "Warning: George Spelikos does not exist in clippings\n",
      "Warning: Georgie Burns does not exist in clippings\n",
      "Warning: Georgie Kaye does not exist in clippings\n",
      "Warning: Gerry Carroll does not exist in clippings\n",
      "Warning: Giggles Craig does not exist in clippings\n",
      "Warning: Gilda Gray does not exist in clippings\n",
      "Warning: Gloria Jean does not exist in clippings\n",
      "Warning: Gorda Davies does not exist in clippings\n",
      "Warning: Gordon Stafford does not exist in clippings\n",
      "Warning: Gus Dreyfus does not exist in clippings\n",
      "Warning: Gypsy Dolan does not exist in clippings\n",
      "Warning: Half-Pint Jaxon does not exist in clippings\n",
      "Warning: Harild Ishem does not exist in clippings\n",
      "Warning: Harold Hesse does not exist in clippings\n",
      "Warning: Harold Ruwin does not exist in clippings\n",
      "Warning: Harri Henri does not exist in clippings\n",
      "Warning: Harry Bernie does not exist in clippings\n",
      "Warning: Harry Brown does not exist in clippings\n",
      "Warning: Harry Dowling does not exist in clippings\n",
      "Warning: Harry E. Brewster does not exist in clippings\n",
      "Warning: Harry Fink does not exist in clippings\n",
      "Warning: Harry Kelly does not exist in clippings\n",
      "Warning: Harry McGhee does not exist in clippings\n",
      "Warning: Harry Pepper does not exist in clippings\n",
      "Warning: Helen Humes does not exist in clippings\n",
      "Warning: Helen Mack does not exist in clippings\n",
      "Warning: Helen Tustin does not exist in clippings\n",
      "Warning: Hemsley Winfield does not exist in clippings\n",
      "Warning: Henri St. Charles does not exist in clippings\n",
      "Warning: Herbert Faye does not exist in clippings\n",
      "Warning: Herman Ferdinand does not exist in clippings\n",
      "Warning: Herslean Roberts does not exist in clippings\n",
      "Warning: Hot-Cha Hinton does not exist in clippings\n",
      "Warning: Howard Blair does not exist in clippings\n",
      "Warning: Howard Parsons does not exist in clippings\n",
      "Warning: Huberta Beeson does not exist in clippings\n",
      "Warning: Ina Gaskill does not exist in clippings\n",
      "Warning: Irvin Mazzie does not exist in clippings\n",
      "Warning: Ivey \"Caldonia\" Anderson does not exist in clippings\n",
      "Warning: J. John Howard does not exist in clippings\n",
      "Warning: J. Sellers does not exist in clippings\n",
      "Warning: J. — does not exist in clippings\n",
      "Warning: Jabby Caruso does not exist in clippings\n",
      "Warning: Jack Carr does not exist in clippings\n",
      "Warning: Jack Craig does not exist in clippings\n",
      "Warning: Jack Hughes does not exist in clippings\n",
      "Warning: Jack King does not exist in clippings\n",
      "Warning: Jack Leystan does not exist in clippings\n",
      "Warning: Jack Mason does not exist in clippings\n",
      "Warning: Jack Polle does not exist in clippings\n",
      "Warning: Jackie Adams does not exist in clippings\n",
      "Warning: Jackie Bennett does not exist in clippings\n",
      "Warning: Jackie Giggles does not exist in clippings\n",
      "Warning: Jackie Hughes does not exist in clippings\n",
      "Warning: Jackie Lane does not exist in clippings\n",
      "Warning: Jackie Law does not exist in clippings\n",
      "Warning: Jackie Lee does not exist in clippings\n",
      "Warning: Jackie Lopez does not exist in clippings\n",
      "Warning: Jackie Lorraine does not exist in clippings\n",
      "Warning: Jackie Lynch does not exist in clippings\n",
      "Warning: Jackie Sawyer does not exist in clippings\n",
      "Warning: Jackie Starr does not exist in clippings\n",
      "Warning: Jackie Thomas does not exist in clippings\n",
      "Warning: Jackie Woods does not exist in clippings\n",
      "Warning: Jacquette La Marr does not exist in clippings\n",
      "Warning: James Carberry does not exist in clippings\n",
      "Warning: James Casalino does not exist in clippings\n",
      "Warning: James Costa does not exist in clippings\n",
      "Warning: James E. Myers does not exist in clippings\n",
      "Warning: James Ernest Allen does not exist in clippings\n",
      "Warning: James Lyons does not exist in clippings\n",
      "Warning: James Riley does not exist in clippings\n",
      "Warning: James Watts does not exist in clippings\n",
      "Warning: Jan Lee does not exist in clippings\n",
      "Warning: Jay Albert does not exist in clippings\n",
      "Warning: Jean Arnold does not exist in clippings\n",
      "Warning: Jean Cook does not exist in clippings\n",
      "Warning: Jean Darling does not exist in clippings\n",
      "Warning: Jean Demeaux does not exist in clippings\n",
      "Warning: Jean Evol does not exist in clippings\n",
      "Warning: Jean Farrelly does not exist in clippings\n",
      "Warning: Jean Jennings does not exist in clippings\n",
      "Warning: Jean La Monte does not exist in clippings\n",
      "Warning: Jean La Rue does not exist in clippings\n",
      "Warning: Jean LaMarr does not exist in clippings\n",
      "Warning: Jean Lures does not exist in clippings\n",
      "Warning: Jean Marlow does not exist in clippings\n",
      "Warning: Jean Osborne does not exist in clippings\n",
      "Warning: Jean Russell does not exist in clippings\n",
      "Warning: Jean Taylor does not exist in clippings\n",
      "Warning: Jean Val Jean does not exist in clippings\n",
      "Warning: Jean — does not exist in clippings\n",
      "Warning: Jene Cortez does not exist in clippings\n",
      "Warning: Jerry Clark does not exist in clippings\n",
      "Warning: Jerry Clayton does not exist in clippings\n",
      "Warning: Jerry Faye does not exist in clippings\n",
      "Warning: Jerry Francis does not exist in clippings\n",
      "Warning: Jerry Girard does not exist in clippings\n",
      "Warning: Jerry King does not exist in clippings\n",
      "Warning: Jerry Lee does not exist in clippings\n",
      "Warning: Jerry Nelson does not exist in clippings\n",
      "Warning: Jerry Podinsky does not exist in clippings\n",
      "Warning: Jerry Sullivan does not exist in clippings\n",
      "Warning: Jerry Trevor does not exist in clippings\n",
      "Warning: Jerry Vaughn does not exist in clippings\n",
      "Warning: Jessie Lee does not exist in clippings\n",
      "Warning: Jessie Rogers does not exist in clippings\n",
      "Warning: Jimmie Bernard does not exist in clippings\n",
      "Warning: Jimmie Gleen does not exist in clippings\n",
      "Warning: Jimmie Sheri does not exist in clippings\n",
      "Warning: Jimmy Carrigan does not exist in clippings\n",
      "Warning: Jimmy Travis does not exist in clippings\n",
      "Warning: Jo-Jo does not exist in clippings\n",
      "Warning: Joan Andrews does not exist in clippings\n",
      "Warning: Joan Rogers does not exist in clippings\n",
      "Warning: Joann O'Brien does not exist in clippings\n",
      "Warning: Joanne does not exist in clippings\n",
      "Warning: Joanne Crawford does not exist in clippings\n",
      "Warning: Joe Canary does not exist in clippings\n",
      "Warning: Joe Cook does not exist in clippings\n",
      "Warning: Joe Hart does not exist in clippings\n",
      "Warning: Joe Johnson does not exist in clippings\n",
      "Warning: Joe Lewis does not exist in clippings\n",
      "Warning: Joe Renard does not exist in clippings\n",
      "Warning: Joe Robinson does not exist in clippings\n",
      "Warning: John Berry does not exist in clippings\n",
      "Warning: John D. May does not exist in clippings\n",
      "Warning: John Dooley does not exist in clippings\n",
      "Warning: John Gravet does not exist in clippings\n",
      "Warning: John Koss does not exist in clippings\n",
      "Warning: John Lonas does not exist in clippings\n",
      "Warning: John St. Leon does not exist in clippings\n",
      "Warning: John Wilton does not exist in clippings\n",
      "Warning: Johnnie Helder does not exist in clippings\n",
      "Warning: Johnnie Langstone does not exist in clippings\n",
      "Warning: Johnny David does not exist in clippings\n",
      "Warning: Johnny Hudgins does not exist in clippings\n",
      "Warning: Johnny Mangum does not exist in clippings\n",
      "Warning: Jose Ayala does not exist in clippings\n",
      "Warning: Jose Del Rio does not exist in clippings\n",
      "Warning: Joseph Bart does not exist in clippings\n",
      "Warning: Joseph Gant does not exist in clippings\n",
      "Warning: Juanita B. Talmadge does not exist in clippings\n",
      "Warning: Jud King does not exist in clippings\n",
      "Warning: Jules Diamond does not exist in clippings\n",
      "Warning: Julia Stevens does not exist in clippings\n",
      "Warning: June Beal does not exist in clippings\n",
      "Warning: Kari Daniels does not exist in clippings\n",
      "Warning: Karlon Owens does not exist in clippings\n",
      "Warning: Keane Waters does not exist in clippings\n",
      "Warning: Kenn King does not exist in clippings\n",
      "Warning: Kenneth D. Custance does not exist in clippings\n",
      "Warning: Kenneth Hawkins does not exist in clippings\n",
      "Warning: Kerri Marlowe does not exist in clippings\n",
      "Warning: Kiki Hall does not exist in clippings\n",
      "Warning: Kitty May does not exist in clippings\n",
      "Warning: Klare Kenney does not exist in clippings\n",
      "Warning: La Carmentita does not exist in clippings\n",
      "Warning: Lady Baltimore does not exist in clippings\n",
      "Warning: Lady Doris does not exist in clippings\n",
      "Warning: Larry Turner does not exist in clippings\n",
      "Warning: Lee Bailey does not exist in clippings\n",
      "Warning: Lee Carroll does not exist in clippings\n",
      "Warning: Lee Moore does not exist in clippings\n",
      "Warning: Lee Robert does not exist in clippings\n",
      "Warning: Leo Fuchs does not exist in clippings\n",
      "Warning: Leo the Lion does not exist in clippings\n",
      "Warning: Leon Dubois does not exist in clippings\n",
      "Warning: Leon Mirabeau does not exist in clippings\n",
      "Warning: Leonard Soules does not exist in clippings\n",
      "Warning: Leslie Lynch does not exist in clippings\n",
      "Warning: Lester Lamont does not exist in clippings\n",
      "Warning: Lester Queen does not exist in clippings\n",
      "Warning: Li Kar does not exist in clippings\n",
      "Warning: Linden does not exist in clippings\n",
      "Warning: Lloyd Woods does not exist in clippings\n",
      "Warning: Lou Lorraine does not exist in clippings\n",
      "Warning: Louis Diggs does not exist in clippings\n",
      "Warning: Louis Edelstein does not exist in clippings\n",
      "Warning: Loyce Trent does not exist in clippings\n",
      "Warning: Lunch Twins does not exist in clippings\n",
      "Warning: Luzetta Hall does not exist in clippings\n",
      "Warning: Lynn & Johnson does not exist in clippings\n",
      "Warning: Lynn Castle does not exist in clippings\n",
      "Warning: Lynn and De Marco does not exist in clippings\n",
      "Warning: Lynne Carter does not exist in clippings\n",
      "Warning: Mack Youge does not exist in clippings\n",
      "['Madam', 'Dubarry', '1']\n",
      "Warning: Madam Dubarry 1 does not exist in clippings\n",
      "['Madam', 'Dubarry', '2']\n",
      "Warning: Madam Dubarry 2 does not exist in clippings\n",
      "Warning: Mae Kelly does not exist in clippings\n",
      "Warning: Manhattan Pearl does not exist in clippings\n",
      "Warning: Manuel DeMonte does not exist in clippings\n",
      "Warning: Margaret Cook does not exist in clippings\n",
      "Warning: Marge Brown does not exist in clippings\n",
      "Warning: Marjoram does not exist in clippings\n",
      "Warning: Martin F. May does not exist in clippings\n",
      "Warning: Martin Wynne does not exist in clippings\n",
      "Warning: Marty Deem does not exist in clippings\n",
      "Warning: Marvene Nelson does not exist in clippings\n",
      "Warning: Mary Brennen does not exist in clippings\n",
      "Warning: Marylin Thomas does not exist in clippings\n",
      "Warning: Matt Berger does not exist in clippings\n",
      "Warning: Max Bellow does not exist in clippings\n",
      "Warning: Max Thorman does not exist in clippings\n",
      "Warning: Maxine does not exist in clippings\n",
      "Warning: Mei Lan-Fang does not exist in clippings\n",
      "Warning: Melba does not exist in clippings\n",
      "Warning: Melvin Evans does not exist in clippings\n",
      "Warning: Michal Michalesko does not exist in clippings\n",
      "Warning: Mickey Dell does not exist in clippings\n",
      "Warning: Mickey Mercer does not exist in clippings\n",
      "Warning: Mickey Nelson does not exist in clippings\n",
      "Warning: Mickey Standley does not exist in clippings\n",
      "Warning: Mickey Strauss does not exist in clippings\n",
      "Warning: Mildred Martin does not exist in clippings\n",
      "Warning: Milton does not exist in clippings\n",
      "Warning: Milton LaMaire does not exist in clippings\n",
      "Warning: Miss Broadway Rose does not exist in clippings\n",
      "Warning: Miss Whitie does not exist in clippings\n",
      "Warning: Mitzi does not exist in clippings\n",
      "Warning: Mitzi Mantis does not exist in clippings\n",
      "Warning: Mona La Fountaine does not exist in clippings\n",
      "Warning: Morris Kinney does not exist in clippings\n",
      "Warning: Mother Smother/Sepia Marlene Dietrich does not exist in clippings\n",
      "Warning: Murray Lenen does not exist in clippings\n",
      "Warning: Murray Swanson does not exist in clippings\n",
      "Warning: Nada Bryant does not exist in clippings\n",
      "Warning: Najean Loy does not exist in clippings\n",
      "Warning: Nancy Cauel does not exist in clippings\n",
      "Warning: Nancy Kelly does not exist in clippings\n",
      "Warning: Nankee Low does not exist in clippings\n",
      "Warning: Naomi Davis does not exist in clippings\n",
      "Warning: Nazi Mova does not exist in clippings\n",
      "Warning: Neil Dornay does not exist in clippings\n",
      "Warning: Nicki Gallucci does not exist in clippings\n",
      "Warning: Niles Marsh does not exist in clippings\n",
      "Warning: Nina Montez does not exist in clippings\n",
      "Warning: Nina Rae does not exist in clippings\n",
      "Warning: Nine Collegians does not exist in clippings\n",
      "Warning: Nora Corona Hancock does not exist in clippings\n",
      "Warning: Norman Lewis does not exist in clippings\n",
      "Warning: Ora Monte does not exist in clippings\n",
      "Warning: Oscar Widmann does not exist in clippings\n",
      "Warning: Page & Hudeck does not exist in clippings\n",
      "Warning: Palafox does not exist in clippings\n",
      "Warning: Palofox does not exist in clippings\n",
      "Warning: Paris Delaire does not exist in clippings\n",
      "Warning: Pat Clayton does not exist in clippings\n",
      "Warning: Pat Paree does not exist in clippings\n",
      "Warning: Patricia Van Dyke does not exist in clippings\n",
      "Warning: Patsy Campbell does not exist in clippings\n",
      "Warning: Patsy Keller does not exist in clippings\n",
      "Warning: Patty Baker does not exist in clippings\n",
      "Warning: Paul does not exist in clippings\n",
      "Warning: Paul Coleman does not exist in clippings\n",
      "Warning: Paul Gilrey does not exist in clippings\n",
      "Warning: Paul La Page does not exist in clippings\n",
      "Warning: Paul Russell does not exist in clippings\n",
      "Warning: Peaches does not exist in clippings\n",
      "Warning: Peaches Browning does not exist in clippings\n",
      "Warning: Peaches Buckingham does not exist in clippings\n",
      "Warning: Peggy Joyce does not exist in clippings\n",
      "Warning: Pepe Blaire does not exist in clippings\n",
      "Warning: Pepper Cortez does not exist in clippings\n",
      "Warning: Peter Joray does not exist in clippings\n",
      "Warning: Petite Swanson does not exist in clippings\n",
      "Warning: Phil Craig does not exist in clippings\n",
      "Warning: Poppy Lane does not exist in clippings\n",
      "Warning: Princess Diane does not exist in clippings\n",
      "Warning: Queen Robi does not exist in clippings\n",
      "Warning: Queenie does not exist in clippings\n",
      "Warning: Ralph Berkowitz does not exist in clippings\n",
      "Warning: Ralph Miller does not exist in clippings\n",
      "Warning: Ram'ee does not exist in clippings\n",
      "Warning: Ramon Strobeck does not exist in clippings\n",
      "Warning: Randi Lete does not exist in clippings\n",
      "Warning: Ray Erline Garrison does not exist in clippings\n",
      "Warning: Ray Foster does not exist in clippings\n",
      "Warning: Ray Francis does not exist in clippings\n",
      "Warning: Ray Hall does not exist in clippings\n",
      "Warning: Ray James does not exist in clippings\n",
      "Warning: Ray Murray does not exist in clippings\n",
      "Warning: Ray Saunders does not exist in clippings\n",
      "Warning: Ray Shannon does not exist in clippings\n",
      "Warning: Red Evans does not exist in clippings\n",
      "Warning: Reeder Richards does not exist in clippings\n",
      "Warning: Reggie \"Dolly\" Windsor does not exist in clippings\n",
      "Warning: Rhodie Kinsella does not exist in clippings\n",
      "Warning: Richard Carlson does not exist in clippings\n",
      "Warning: Richard Lansin does not exist in clippings\n",
      "Warning: Richard McLean does not exist in clippings\n",
      "Warning: Richard Snooks Davis does not exist in clippings\n",
      "Warning: Robert A. Lyons does not exist in clippings\n",
      "Warning: Robert Fagan does not exist in clippings\n",
      "Warning: Robert Long does not exist in clippings\n",
      "Warning: Robert P. Philip does not exist in clippings\n",
      "Warning: Rocky twins does not exist in clippings\n",
      "Warning: Rodney Griffin does not exist in clippings\n",
      "Warning: Roger Davis does not exist in clippings\n",
      "Warning: Rollie Andrews does not exist in clippings\n",
      "Warning: Roxy does not exist in clippings\n",
      "Warning: Roxy King does not exist in clippings\n",
      "Warning: Roy Whitemore does not exist in clippings\n",
      "Warning: Ruth Roberts does not exist in clippings\n",
      "Warning: Found matching clippings folder with wrong name, so decoupling: Sally ≠ sally's hideaway [venue]\n",
      "Warning: Sam Silvers does not exist in clippings\n",
      "Warning: Sammy Grand does not exist in clippings\n",
      "Warning: Sammy Lewis does not exist in clippings\n",
      "Warning: Sandra does not exist in clippings\n",
      "Warning: Satch and Satchell does not exist in clippings\n",
      "Warning: Shirline does not exist in clippings\n",
      "Warning: Skelly does not exist in clippings\n",
      "Warning: Soni Sinclair does not exist in clippings\n",
      "Warning: Sonny La Rae does not exist in clippings\n",
      "Warning: Sonny O'Shea does not exist in clippings\n",
      "Warning: Sonny Teal does not exist in clippings\n",
      "Warning: Stanley E. Caulfield does not exist in clippings\n",
      "Warning: Stanley Jabin does not exist in clippings\n",
      "Warning: Steel Smith does not exist in clippings\n",
      "Warning: Stuart P. Murphy does not exist in clippings\n",
      "Warning: Sunny La Ray does not exist in clippings\n",
      "Warning: Sweet Mama Sue does not exist in clippings\n",
      "Warning: Syd Chaplin does not exist in clippings\n",
      "Warning: T. C. Jones does not exist in clippings\n",
      "Warning: Tanya Garth does not exist in clippings\n",
      "Warning: Ted Cook does not exist in clippings\n",
      "Warning: Ted Lewis does not exist in clippings\n",
      "Warning: Ted Richards does not exist in clippings\n",
      "Warning: Ted Shaw does not exist in clippings\n",
      "Warning: Teddy Cappy does not exist in clippings\n",
      "Warning: Teddy Hayes does not exist in clippings\n",
      "Warning: Teddy Keller does not exist in clippings\n",
      "Warning: Teddy — does not exist in clippings\n",
      "Warning: Terry Lane does not exist in clippings\n",
      "Warning: Terry Phillips does not exist in clippings\n",
      "Warning: Terry Stone does not exist in clippings\n",
      "Warning: Terry Tremaine does not exist in clippings\n",
      "Warning: Tess Russell does not exist in clippings\n",
      "Warning: Tex Hendricks does not exist in clippings\n",
      "Warning: The Duchess does not exist in clippings\n",
      "Warning: The Great Melba does not exist in clippings\n",
      "Warning: The Mystery Dancer does not exist in clippings\n",
      "Warning: Thelma Lee does not exist in clippings\n",
      "Warning: Thelma the Great does not exist in clippings\n",
      "Warning: Thetis Storey does not exist in clippings\n",
      "Warning: Thomas Martin does not exist in clippings\n",
      "Warning: Thompson Twin 1 does not exist in clippings\n",
      "Warning: Thompson Twin 2 does not exist in clippings\n",
      "Warning: Tiny Kingsmore does not exist in clippings\n",
      "Warning: Titanic Kit Russell does not exist in clippings\n",
      "Warning: Toley-Goodie-Goodie-Waddel does not exist in clippings\n",
      "Warning: Tom Hose does not exist in clippings\n",
      "Warning: Tommy Lester does not exist in clippings\n",
      "Warning: Tommy Mann does not exist in clippings\n",
      "Warning: Toni Midnite does not exist in clippings\n",
      "Warning: Tony Collins does not exist in clippings\n",
      "Warning: Tony Karol does not exist in clippings\n",
      "Warning: Toots does not exist in clippings\n",
      "Warning: Val Turek does not exist in clippings\n",
      "Warning: Val Varr does not exist in clippings\n",
      "Warning: Valda Gray does not exist in clippings\n",
      "Warning: Vera Mazzie does not exist in clippings\n",
      "Warning: Verida Pearson does not exist in clippings\n",
      "Warning: Vernon Fountain does not exist in clippings\n",
      "Warning: Vicki does not exist in clippings\n",
      "Warning: Vincent McFarland does not exist in clippings\n",
      "Warning: Vincent Reid does not exist in clippings\n",
      "Warning: Viola Layne does not exist in clippings\n",
      "Warning: Violet Clements does not exist in clippings\n",
      "Warning: Wallace Reed does not exist in clippings\n",
      "Warning: Wallie Groff does not exist in clippings\n",
      "Warning: Wally Brennan does not exist in clippings\n",
      "Warning: Wally Thompson does not exist in clippings\n",
      "Warning: Walter Hart does not exist in clippings\n",
      "Warning: Walter McDonald does not exist in clippings\n",
      "Warning: Walter Morgan does not exist in clippings\n",
      "Warning: Walter Munde does not exist in clippings\n",
      "Warning: Walter Thomas does not exist in clippings\n",
      "Warning: Weldon Short does not exist in clippings\n",
      "Warning: Wesley Davis does not exist in clippings\n",
      "Warning: Whitey Harris does not exist in clippings\n",
      "Warning: Wilkie Mason does not exist in clippings\n",
      "Warning: William Green does not exist in clippings\n",
      "Warning: William Harris does not exist in clippings\n",
      "Warning: William Johnson does not exist in clippings\n",
      "Warning: William Lee Becker does not exist in clippings\n",
      "Warning: Willie Duices does not exist in clippings\n",
      "Warning: Yvonne — does not exist in clippings\n",
      "Warning: Zalman does not exist in clippings\n",
      "Warning: Zorina La Cross does not exist in clippings\n",
      "Warning: [Harold Shinn] does not exist in clippings\n",
      "Warning: — Alexandria does not exist in clippings\n",
      "Warning: — Brennan does not exist in clippings\n",
      "Warning: — Dion does not exist in clippings\n",
      "Warning: — Enesco does not exist in clippings\n",
      "Warning: — Gresham does not exist in clippings\n",
      "Warning: — King does not exist in clippings\n",
      "Warning: — Knox does not exist in clippings\n",
      "Warning: — Lacy does not exist in clippings\n",
      "Warning: — Leslie does not exist in clippings\n",
      "Warning: — Lewis does not exist in clippings\n",
      "Warning: — Mack does not exist in clippings\n",
      "Warning: — Marion does not exist in clippings\n",
      "Warning: — Marshall does not exist in clippings\n",
      "Warning: — Mitchell does not exist in clippings\n",
      "Warning: — Satch does not exist in clippings\n",
      "Warning: — Satchell does not exist in clippings\n",
      "Warning: — Williams does not exist in clippings\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def make_all_clippings():\n",
    "    import glob\n",
    "    \n",
    "    try:\n",
    "        from IPython.display import clear_output\n",
    "        ipython = True\n",
    "    except:\n",
    "        ipython = False\n",
    "    files = {}\n",
    "    ARCHIVE_FOLDERS = [x for x in glob.glob('/Volumes/GoogleDrive/My Drive/Ongoing Projects/Dissertation - Archive/- My own clippings and photos/*')]\n",
    "    FILE_COMMENT = re.compile(r'(.*) ?\\[(.*)\\]')\n",
    "    categories = {None: {None: []}}\n",
    "    for folder_count, name in enumerate(ARCHIVE_FOLDERS):\n",
    "        if ipython:\n",
    "            print(f'{folder_count}/{len(ARCHIVE_FOLDERS)}: {name}')\n",
    "            clear_output(wait=True)\n",
    "        if FILE_COMMENT.search(name):\n",
    "            folder, category = FILE_COMMENT.search(name).groups()\n",
    "            clean_folder_name = Path(folder).name.strip()\n",
    "            print(clean_folder_name)\n",
    "            folder_categories = [x.strip() for x in category.split(';')]\n",
    "            primary_cat = folder_categories.pop(0)\n",
    "            if not primary_cat in categories:\n",
    "                categories[primary_cat] = {None: []}\n",
    "            if not folder_categories:\n",
    "                categories[primary_cat][None].append(clean_folder_name)\n",
    "            else:\n",
    "                if not '; '.join(folder_categories) in categories[primary_cat]:\n",
    "                    categories[primary_cat]['; '.join(folder_categories)] = []\n",
    "                categories[primary_cat]['; '.join(folder_categories)].append(clean_folder_name)\n",
    "        else:\n",
    "            categories[None].append(Path(name).name.strip())\n",
    "\n",
    "        p = Path(name)\n",
    "        files[p.name] = [x.name for x in p.glob('**/*') if x.is_file() and not x.name.startswith('.')]\n",
    "        \n",
    "        _ = {}\n",
    "\n",
    "    for cat in sorted([str(x) for x in categories.keys()]):\n",
    "        if cat == 'None':\n",
    "            cat = None\n",
    "        for subcat in sorted([str(x) for x in categories[cat].keys()]):\n",
    "            if subcat == 'None':\n",
    "                subcat = None\n",
    "            if not cat in _:\n",
    "                _[cat] = {}\n",
    "            _[cat][subcat] = categories[cat][subcat]\n",
    "\n",
    "    return _, files\n",
    "    \n",
    "e.globals['ALL_CLIPPINGS'], e.globals['ALL_CLIPPINGS_FILES'] = make_all_clippings()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bell, Bobby\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "if not Path(DATASET_OUTPUT_DIR).exists():\n",
    "    Path(DATASET_OUTPUT_DIR).mkdir(parents=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "from htmlmin import minify as minify_html\n",
    "\n",
    "def minify_html(text):\n",
    "    return text\n",
    "\n",
    "BASE_URL = '/docs/' # '/docs/' or '/drag-data-browser/'\n",
    "DATASET_URL = BASE_URL + 'dataset/'\n",
    "CASE_STUDY_URL = BASE_URL + 'case-study/'\n",
    "DATA_URL = BASE_URL + 'data/'\n",
    "\n",
    "e.globals['BASE_URL'] = BASE_URL\n",
    "e.globals['DATASET_URL'] = DATASET_URL\n",
    "e.globals['CASE_STUDY_URL'] = CASE_STUDY_URL\n",
    "e.globals['DATA_URL'] = DATA_URL\n",
    "\n",
    "e.globals['DATA_SHEET'] = 'https://docs.google.com/spreadsheets/d/1UlpFQ9WWA6_6X-RuMJ3vHdIbyqhCZ1VRYgcQYjXprAg/edit'\n",
    "\n",
    "e.globals['SITE_TITLE'] = \"Gayboys and Playboys\"\n",
    "e.globals['SITE_SUBTITLE'] = \"Expanding the Field of U.S. Drag Performers in 1930s Burlesque and Night Clubs\"\n",
    "\n",
    "e.globals['NAVBAR'] = {\n",
    "    'width': 280,\n",
    "    'structure': {\n",
    "        'Case Studies': [\n",
    "            {\n",
    "                'icon': 'case-study',\n",
    "                'title': 'Intimate Accoutrements as Somatechnical Network Devices',\n",
    "                'url': CASE_STUDY_URL + 'intimate-accoutrements-as-somatechnical-network-devices/',\n",
    "                'subcategories': []\n",
    "            },{\n",
    "                'icon': 'case-study',\n",
    "                'title': '“An Expanse of Hairy Chest Above a Beaded Brassiere”',\n",
    "                'url': CASE_STUDY_URL + 'an-expanse-of-hairy-chest-above-a-beaded-brassiere/',\n",
    "                'subcategories': []\n",
    "            },{\n",
    "                'icon': 'case-study',\n",
    "                'title': 'Camping in the Clubs and the County Courts',\n",
    "                'url': CASE_STUDY_URL + 'camping-in-the-clubs-and-the-county-courts/',\n",
    "                'subcategories': []\n",
    "            },{\n",
    "                'icon': 'case-study',\n",
    "                'title': '“See it—Live it—Dance it”',\n",
    "                'url': CASE_STUDY_URL + 'see-it-live-it-dance-it/',\n",
    "                'subcategories': []\n",
    "            },\n",
    "        ],\n",
    "        'Visualizations': [\n",
    "            {\n",
    "                'icon': 'network',\n",
    "                'title': 'Network',\n",
    "                'url': BASE_URL + 'network/',\n",
    "                'subcategories': [\n",
    "                    {\n",
    "                        'title': 'Community Distribution',\n",
    "                        'url': BASE_URL + 'network/community-distribution/'\n",
    "                    },\n",
    "                    {\n",
    "                        'title': 'Network Overview',\n",
    "                        'url': BASE_URL + 'network/overview/'\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'icon': 'speedometer2',\n",
    "                'title': 'Continuous Performers',\n",
    "                'url': BASE_URL + 'continuous-performers/',\n",
    "                'subcategories': []\n",
    "            },\n",
    "            {\n",
    "                'icon': 'globe',\n",
    "                'title': 'Geodata (alpha)',\n",
    "                'url': BASE_URL + 'geo/',\n",
    "                'subcategories': []\n",
    "            },\n",
    "            {\n",
    "                'icon': 'process',\n",
    "                'title': 'Research Process',\n",
    "                'url': BASE_URL + 'process/',\n",
    "                'subcategories': []\n",
    "            }\n",
    "        ],\n",
    "        'Data': [\n",
    "            {\n",
    "                'icon': 'dataset',\n",
    "                'title': 'Dataset',\n",
    "                'url': DATASET_URL + '',\n",
    "                'subcategories': [\n",
    "                    {\n",
    "                        'title': 'Performers',\n",
    "                        'url': DATASET_URL + 'performer/'\n",
    "                    },\n",
    "                    {\n",
    "                        'title': 'Venues',\n",
    "                        'url': DATASET_URL + 'venue/'\n",
    "                    },\n",
    "                    {\n",
    "                        'title': 'Similar name reports',\n",
    "                        'url': BASE_URL + 'similar-names/'\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'icon': 'clippings',\n",
    "                'title': 'Clippings',\n",
    "                'url': DATASET_URL + 'clippings/',\n",
    "                'subcategories': []\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "\n",
    "performer_template = e.get_template('dataset/performer.html')\n",
    "\n",
    "\n",
    "performers_active_dates_overview = {}\n",
    "\n",
    "def slugify_node(value, allow_unicode=False, verbose=False):\n",
    "    import unicodedata\n",
    "    ''' this function comes from generate-cooccurrence-data.py '''\n",
    "    init_value = str(value)\n",
    "    value = init_value\n",
    "    value = (\n",
    "        unicodedata.normalize(\"NFKD\", value).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    )\n",
    "    value = re.sub(r\"[^\\w\\s-]\", \"\", value.lower())\n",
    "    value = re.sub(r\"^(\\d+)\", r\"n\\1\", value)\n",
    "    value = re.sub(r\"[-\\s]+\", \"_\", value).strip(\"-_\")\n",
    "    if verbose:\n",
    "        print(f\"Making slug from {init_value}: {value}\")\n",
    "    return value\n",
    "\n",
    "\n",
    "for performer, row in df.groupby(['Performer']):\n",
    "    if not performer:\n",
    "        continue\n",
    "\n",
    "    html_file = os.path.join(DATASET_OUTPUT_DIR, 'performer', ALL_PERFORMERS[performer], 'index.html')\n",
    "    if not Path(html_file).parent.exists():\n",
    "        Path(html_file).parent.mkdir(parents=True)\n",
    "    \n",
    "    full_venues = list(set([x for x in row['Unique venue'] if x and not x.startswith('—')]))\n",
    "    full_venues = {x: ALL_VENUES[x] for x in full_venues}\n",
    "\n",
    "    cities = list(set([x for x in row['City'] if x]))\n",
    "    years_active = list(set(([x.year for x in pd.to_datetime(row['Date'])])))\n",
    "    appears_at = list(set([x for x in row['Venue'] if x]))\n",
    "    \n",
    "    performers_active_dates_overview[performer] = years_active\n",
    "\n",
    "    next_performer = keyshift(ALL_PERFORMERS, performer, +1)\n",
    "    prev_performer = keyshift(ALL_PERFORMERS, performer, -1)\n",
    "    if next_performer:\n",
    "        next_performer = {'label': next_performer, 'url': DATASET_URL + 'performer/' + ALL_PERFORMERS[next_performer]}\n",
    "    if prev_performer:\n",
    "        prev_performer = {'label': prev_performer, 'url': DATASET_URL + 'performer/' + ALL_PERFORMERS[prev_performer]}\n",
    "    \n",
    "    text = performer_template.render(data={\n",
    "        'name': performer,\n",
    "        'node_id': slugify_node(performer),\n",
    "        'years_active': years_active,\n",
    "        'full_venues': full_venues,\n",
    "        'cities': cities,\n",
    "        'in_blackface': blackface_performers.get(performer, {}),\n",
    "        'sepia_performer': sepia_performers.get(performer, {}),\n",
    "        'fan_dancer': fan_dance_performers.get(performer, {}),\n",
    "        'exotic_dancer': exotic_dancers.get(performer, {}),\n",
    "        'images': has_image.get(performer, {}),\n",
    "        'comments': e.globals['PERFORMER_COMMENTS'].get(performer, {}),\n",
    "        'legal_name': legal_names.get(performer, {}),\n",
    "        'age': ages.get(performer, {}),\n",
    "        'birth_year': birth_years.get(performer, {}),\n",
    "        'relative': {\n",
    "            'next': next_performer,\n",
    "            'prev': prev_performer\n",
    "        }\n",
    "    })\n",
    "\n",
    "    with open(html_file, 'w+') as f:\n",
    "        f.write(minify_html(text))\n",
    "        \n",
    "        \n",
    "        \n",
    "########################\n",
    "\n",
    "\n",
    "venue_template = e.get_template('dataset/venue.html')\n",
    "\n",
    "\n",
    "venues_active_dates_overview = {}\n",
    "\n",
    "for venue, row in df.groupby(['Unique venue']):\n",
    "    if not venue or venue.startswith('—'):\n",
    "        continue\n",
    "\n",
    "    html_file = os.path.join(DATASET_OUTPUT_DIR, 'venue', ALL_VENUES[venue], 'index.html')\n",
    "    if not Path(html_file).parent.exists():\n",
    "        Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "    associated_performers = list(set([x for x in row['Performer'] if x]))\n",
    "    associated_performers = {x: ALL_PERFORMERS[x] for x in associated_performers}\n",
    "    years_active = list(set(([x.year for x in pd.to_datetime(row['Date'])])))\n",
    "    \n",
    "    venues_active_dates_overview[venue] = years_active\n",
    "    \n",
    "    next_venue = keyshift(ALL_VENUES, venue, +1)\n",
    "    prev_venue = keyshift(ALL_VENUES, venue, -1)\n",
    "    if next_venue:\n",
    "        next_venue = {'label': next_venue, 'url': DATASET_URL + 'venue/' + ALL_VENUES[next_venue]}\n",
    "    if prev_venue:\n",
    "        prev_venue = {'label': prev_venue, 'url': DATASET_URL + 'venue/' + ALL_VENUES[prev_venue]}\n",
    "    \n",
    "    text = venue_template.render(data={\n",
    "        'name': venue,\n",
    "        'years_active': years_active,\n",
    "        'associated_performers': associated_performers,\n",
    "        'addresses': addresses.get(venue, {}),\n",
    "        'comments': venue_comments.get(venue, {}),\n",
    "        'relative': {\n",
    "            'next': next_venue,\n",
    "            'prev': prev_venue,\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    with open(html_file, 'w+') as f:\n",
    "        f.write(minify_html(text))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "MIN = min(list(itertools.chain.from_iterable(venues_active_dates_overview.values())))\n",
    "MAX = max(list(itertools.chain.from_iterable(venues_active_dates_overview.values())))\n",
    "        \n",
    "venue_list_template = e.get_template('dataset/venue-list.html')\n",
    "\n",
    "html_file = os.path.join(DATASET_OUTPUT_DIR, 'venue', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = venue_list_template.render(data={\n",
    "    'venues_active_dates_overview': venues_active_dates_overview,\n",
    "    'venues_years_range': [x for x in range(MIN,MAX)]\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "MIN = min(list(itertools.chain.from_iterable(performers_active_dates_overview.values())))\n",
    "MAX = max(list(itertools.chain.from_iterable(performers_active_dates_overview.values())))\n",
    "        \n",
    "performer_list_template = e.get_template('dataset/performer-list.html')\n",
    "\n",
    "html_file = os.path.join(DATASET_OUTPUT_DIR, 'performer', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = performer_list_template.render(data={\n",
    "    'performers_active_dates_overview': performers_active_dates_overview,\n",
    "    'performer_years_range': [x for x in range(MIN,MAX)]\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "template = e.get_template('dataset/clippings.html')\n",
    "\n",
    "html_file = os.path.join(DATASET_OUTPUT_DIR, 'clippings', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={\n",
    "    \n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "calendar_template = e.get_template('dataset/calendar.html')\n",
    "\n",
    "html_file = os.path.join(DATASET_OUTPUT_DIR, 'calendar', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = calendar_template.render(data={\n",
    "    \n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('dataset/home.html')\n",
    "\n",
    "html_file = os.path.join(DATASET_OUTPUT_DIR, 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={\n",
    "    'xxx': 'xxx'\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('viz/continuous-performers.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'continuous-performers', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={\n",
    "    'leads': {\n",
    "        0: '''This is the dataset's actual content. Each dot represents each month where the artist selected appears in the dataset.''',\n",
    "        1: '''The padding of the dataset here ranges ±1 month, which means that if the selected artist appeared in one month in the dataset, it is assumed that the same artist appeared in the surrounding two months (1 month before and 1 month after the date in the dataset).''',\n",
    "        2: '''The padding of the dataset here ranges ±2 months, which means that if the selected artist appeared in one month in the dataset, it is assumed that the same artist appeared in the surrounding four months (2 months before and 2 months after the date in the dataset).''',\n",
    "        3: '''The padding of the dataset here ranges ±3 months, which means that if the selected artist appeared in one month in the dataset, it is assumed that the same artist appeared in the surrounding six months (3 months before and 3 months after the date in the dataset).''',\n",
    "        4: '''The padding of the dataset here ranges ±4 months, which means that if the selected artist appeared in one month in the dataset, it is assumed that the same artist appeared in the surrounding eight months (4 months before and 4 months after the date in the dataset).''',\n",
    "        5: '''The padding of the dataset here ranges ±5 months, which means that if the selected artist appeared in one month in the dataset, it is assumed that the same artist appeared in the surrounding ten months (5 months before and 5 months after the date in the dataset).'''\n",
    "    }\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "# Copy drag-network into the html here too\n",
    "\n",
    "if Path('../drag-network').exists():\n",
    "    import shutil\n",
    "    def copy_and_overwrite(from_path, to_path):\n",
    "        if os.path.exists(to_path):\n",
    "            shutil.rmtree(to_path)\n",
    "        shutil.copytree(from_path, to_path)\n",
    "\n",
    "    copy_and_overwrite('../drag-network', OUTPUT_DIR + 'network')\n",
    "    Path(OUTPUT_DIR + 'network/index.html').unlink()\n",
    "\n",
    "    from shutil import copyfile\n",
    "    for file in [x for x in Path('../drag-network/data').glob('*.json')]:\n",
    "        copyfile(file, f'../docs/data/{file.name}')\n",
    "    for file in [x for x in Path('../drag-network/data/individual-networks/v1-co-occurrence-grouped-by-14-days-no-unnamed-performers/').glob('*.json')]:\n",
    "        copyfile(file, f'../docs/data/individual-networks/{file.name}')\n",
    "else:\n",
    "    print('Warning: add `drag-network` repository as a submodule before running this script.')\n",
    "    print('git submodule add https://www.github.com/kallewesterling/drag-network')\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('viz/network.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'network', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "template = e.get_template('viz/network-community-distribution.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'network', 'community-distribution', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "template = e.get_template('viz/network-overview.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'network', 'overview', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Copy drag-network into the html here too\n",
    "\n",
    "if Path('../drag-geo').exists():\n",
    "    import shutil\n",
    "    def copy_and_overwrite(from_path, to_path):\n",
    "        if os.path.exists(to_path):\n",
    "            shutil.rmtree(to_path)\n",
    "        shutil.copytree(from_path, to_path)\n",
    "\n",
    "    copy_and_overwrite('../drag-geo', OUTPUT_DIR + 'geo')\n",
    "    Path(OUTPUT_DIR + 'geo/index.html').unlink()\n",
    "\n",
    "    from shutil import copyfile\n",
    "    for file in [x for x in Path('../drag-geo/data').glob('*') if not 'co-occurrence' in x.name and not x.name.startswith('.')]:\n",
    "        print(file)\n",
    "        copyfile(file, f'../docs/data/{file.name}')\n",
    "else:\n",
    "    print('Warning: add `drag-geo` repository as a submodule before running this script.')\n",
    "    print('git submodule add https://www.github.com/kallewesterling/drag-geo')\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('viz/geo.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'geo', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={\n",
    "    'xxx': 'xxx'\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('home.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={\n",
    "\n",
    "    'xxx': 'xxx'\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('about.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'about', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={\n",
    "    'xxx': 'xxx'\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "home_template = e.get_template('viz/process.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'process', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = home_template.render(data={\n",
    "    'xxx': 'xxx'\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "case_study_titles = {\n",
    "    1: {\n",
    "        'title': 'Intimate Accoutrements as Somatechnical Network Devices',\n",
    "        'subtitle': 'Through High Heels and Rubber Breasts to the Collective',\n",
    "        'url': 'intimate-accoutrements-as-somatechnical-network-devices',\n",
    "        'json': '../docs/data/case-study-1.json'\n",
    "    },\n",
    "    2: {\n",
    "        'title': '“An Expanse of Hairy Chest Above a Beaded Brassiere”',\n",
    "        'subtitle': 'Bobby Morris’s Burlesque Drag Striptease',\n",
    "        'url': 'an-expanse-of-hairy-chest-above-a-beaded-brassiere',\n",
    "        'json': '../docs/data/case-study-2.json'\n",
    "    },\n",
    "    3: {\n",
    "        'title': 'Camping in the Clubs and the County Courts',\n",
    "        'subtitle': 'Taming the Wild Gender of the Playboy Revue',\n",
    "        'url': 'camping-in-the-clubs-and-the-county-courts',\n",
    "        'json': '../docs/data/case-study-3.json'\n",
    "    },\n",
    "    4: {\n",
    "        'title': '“See it—Live it—Dance it”',\n",
    "        'subtitle': 'Peripatetic Queer World-Making in Fay Norman’s Gay Boy Revue',\n",
    "        'url': 'see-it-live-it-dance-it',\n",
    "        'json': '../docs/data/case-study-4.json'\n",
    "    },\n",
    "}\n",
    "\n",
    "ARTISTS = re.compile(r'\\[\\[(?:[^|\\]]*\\|)?([^\\]]+)\\]\\]') # follows wikipedia standard\n",
    "FOOTNOTES = re.compile(r'\\[fn=([^\\[]+)\\]')\n",
    "\n",
    "\n",
    "with open('../docs/data/case-study-footnotes.json', 'r') as f:\n",
    "    footnote_dir = json.loads(f.read())\n",
    "\n",
    "def lookup_footnote(footnote, footnote_dir=footnote_dir, get_field=\"fullReference\"):\n",
    "    footnote_looked_up = footnote_dir.get(footnote, {})\n",
    "    if footnote_looked_up.get(get_field):\n",
    "        return footnote_looked_up.get(get_field)\n",
    "    else:\n",
    "        return f'Error: {get_field} for footnote {footnote} could not be found.'\n",
    "\n",
    "\n",
    "\n",
    "case_studies = {}\n",
    "\n",
    "for case_study_number in [4, 3, 1, 2]:\n",
    "    template = e.get_template('case-study/case-study.html')\n",
    "\n",
    "    html_file = os.path.join(OUTPUT_DIR, 'case-study', case_study_titles[case_study_number]['url'], 'index.html')\n",
    "    if not Path(html_file).parent.exists():\n",
    "        Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "    try:\n",
    "        with open(case_study_titles[case_study_number]['json'], 'r') as f:\n",
    "            chapter = json.loads(f.read())\n",
    "    except:\n",
    "        print('file not found', case_study_titles[case_study_number]['json'])\n",
    "        chapter = {}\n",
    "\n",
    "    sections = []\n",
    "    for section in chapter.get('sections', []):\n",
    "        slugified = slugify(section['title'])\n",
    "        sections.append((section['title'], slugified))\n",
    "        section['slug'] = slugified\n",
    "        for ix, paragraph in enumerate(section['paragraphs']):\n",
    "            if paragraph.endswith('.png'):\n",
    "                section['paragraphs'][ix] = f'<img src=\"{BASE_URL}data/case-study-{case_study_number}/{section[\"paragraphs\"][ix]}\" class=\"border shadow-sm rounded-3\" />'\n",
    "            if paragraph.startswith('<'):\n",
    "                pass\n",
    "            else:\n",
    "                section['paragraphs'][ix] = f'<p>{ paragraph }</p>'\n",
    "\n",
    "    all_footnotes = []\n",
    "    for section in chapter.get('sections', []):\n",
    "        for ix, para in enumerate(section['paragraphs']):\n",
    "            for found_artist in ARTISTS.findall(para):\n",
    "                try:\n",
    "                    performer_slug = get_performer_slug(found_artist)\n",
    "                except:\n",
    "                    performer_slug = None\n",
    "                \n",
    "                if performer_slug:\n",
    "                    section['paragraphs'][ix] = para.replace(f'[[{found_artist}]]', f'<a href=\"{ DATASET_URL }performer/{performer_slug}\">{found_artist}</a>')\n",
    "            for footnote in FOOTNOTES.findall(para):\n",
    "                orig_footnote = footnote\n",
    "                if footnote.startswith('{') and footnote.endswith('}'):\n",
    "                    footnote = lookup_footnote(footnote[1:-1])\n",
    "                all_footnotes.append(footnote)\n",
    "                section['paragraphs'][ix] = section['paragraphs'][ix].replace(f'[fn={orig_footnote}]', f'<sup><a id=\"inlineFootnote{len(all_footnotes)}\" href=\"#fn{len(all_footnotes)}\" class=\"text-decoration-none text-secondary\">{len(all_footnotes)}</a></sup>')\n",
    "\n",
    "    case_study_data = {\n",
    "        'title': case_study_titles[case_study_number]['title'],\n",
    "        'subtitle': case_study_titles[case_study_number]['subtitle'],\n",
    "        'sections': sections,\n",
    "        'chapter': chapter,\n",
    "        'url': case_study_titles[case_study_number]['url'],\n",
    "        'footnotes': {counter: footnote for counter, footnote in enumerate(all_footnotes, start=1)}\n",
    "    }\n",
    "    \n",
    "    if not case_study_data['chapter'].get('abstract'):\n",
    "        from bs4 import BeautifulSoup\n",
    "        import bs4\n",
    "\n",
    "        soup = BeautifulSoup(case_study_data['chapter']['sections'][0]['paragraphs'][0])\n",
    "        text = []\n",
    "        for x in soup.html.body.p.children:\n",
    "            if isinstance(x, bs4.element.NavigableString):\n",
    "                text.append(x.strip())\n",
    "        case_study_data['chapter']['abstract'] = \" \".join(text)\n",
    "\n",
    "    case_studies[case_study_number] = case_study_data\n",
    "\n",
    "    text = template.render(data=case_study_data)\n",
    "\n",
    "    with open(html_file, 'w+') as f:\n",
    "        f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "template = e.get_template('case-study/index.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'case-study', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={\n",
    "    'case_studies': {k: case_studies[k] for k in sorted(case_studies.keys())}\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "with open('../docs/data/v1-report-similar-names.json', 'r') as f:\n",
    "    v1_similar_names = json.loads(f.read())\n",
    "    _v1_similar_names = []\n",
    "    collected = []\n",
    "    for x, y, z, aa, bb in v1_similar_names:\n",
    "        if not (x,y) in collected and not (y,x) in collected:\n",
    "            collected.append((x,y))\n",
    "            _v1_similar_names.append((x, y, z, aa, bb))\n",
    "\n",
    "    v1_similar_names = _v1_similar_names\n",
    "\n",
    "with open('../docs/data/live-report-similar-names.json', 'r') as f:\n",
    "    live_similar_names = json.loads(f.read())\n",
    "    _live_similar_names = []\n",
    "    collected = []\n",
    "    for x, y, z, aa, bb in live_similar_names:\n",
    "        if not (x,y) in collected and not (y,x) in collected:\n",
    "            collected.append((x,y))\n",
    "            _live_similar_names.append((x, y, z, aa, bb))\n",
    "\n",
    "    live_similar_names = _live_similar_names\n",
    "\n",
    "template = e.get_template('similar-names.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'similar-names', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={\n",
    "    'v1': [(x, y, round((z * 100), 2), nb1, nb2) for x,y,z,nb1,nb2 in v1_similar_names],\n",
    "    'live': [(x, y, round((z * 100), 2), nb1, nb2) for x,y,z,nb1,nb2 in live_similar_names],\n",
    "})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "template = e.get_template('code/index.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'code', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n",
    "\n",
    "\n",
    "template = e.get_template('code/continuous-performers.html')\n",
    "\n",
    "html_file = os.path.join(OUTPUT_DIR, 'code', 'continuous-performers', 'index.html')\n",
    "if not Path(html_file).parent.exists():\n",
    "    Path(html_file).parent.mkdir(parents=True)\n",
    "\n",
    "text = template.render(data={})\n",
    "\n",
    "with open(html_file, 'w+') as f:\n",
    "    f.write(minify_html(text))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../drag-geo/data/USA_Major_Cities.geojson\n",
      "../drag-geo/data/geolocated_performers.csv\n",
      "../drag-geo/data/us.json\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "sources = list(set(sorted(list(set([x for x in df['Source']])))))\n",
    "for source in sources:\n",
    "    s = re.split(', (January|February|March|April|May|June|July|August|September|October|November|December)', source)[0]\n",
    "    if ',' in s or '(' in s:\n",
    "        if not s.startswith('-') and not s.startswith('Letter from') and not s.startswith('Telegram from'):\n",
    "            print(s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variety, Feb XX, 1933, page unknown\n",
      "Whittier News, 8 (Paul Harrison, \"In New York\", 627840200)\n",
      "Tristan Cabello, \"Queer Bronzeville,\" OutHistory, no date\n",
      "Promotional Postcard, Brooklyn Academy of Music, 1949 (BAM Archives)\n",
      "Berwyn IL Life, October 9, 1936, 10 (523669010)\n",
      "The Harlequin's Installation Revel, at the Masquers\n",
      "Portland ME Press Herald. December 12, 1949, 19 (9018859)\n",
      "Albany NY Times-Union, date unknown\n",
      "Troy NY Times Record, date unclear [very likely end of February 1940], 8\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "interpreter": {
   "hash": "e2492d90a0e4d5066ae5153b223475f66c93218433dc322da607b5802c2cc184"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}